package services

import (
	"fmt"
	"log"
	"math"
	"sort"
	"strings"
	"time"

	"hunt-chat-api/pkg/models"

	"github.com/google/uuid"
)

// StatisticsService çµ±è¨ˆåˆ†æã‚µãƒ¼ãƒ“ã‚¹
type StatisticsService struct {
	weatherService     *WeatherService
	azureOpenAIService *AzureOpenAIService
}

// NewStatisticsService æ–°ã—ã„çµ±è¨ˆåˆ†æã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½œæˆ
func NewStatisticsService(weatherService *WeatherService, azureOpenAIService *AzureOpenAIService) *StatisticsService {
	return &StatisticsService{
		weatherService:     weatherService,
		azureOpenAIService: azureOpenAIService,
	}
}

// CalculateCorrelation 2ã¤ã®ãƒ‡ãƒ¼ã‚¿ç³»åˆ—ã®ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—
func (s *StatisticsService) CalculateCorrelation(x, y []float64) (float64, error) {
	if len(x) != len(y) || len(x) == 0 {
		return 0, fmt.Errorf("ãƒ‡ãƒ¼ã‚¿ç³»åˆ—ã®é•·ã•ãŒä¸€è‡´ã—ãªã„ã‹ã€ç©ºã§ã™")
	}

	n := float64(len(x))
	var sumX, sumY, sumXY, sumX2, sumY2 float64

	for i := 0; i < len(x); i++ {
		sumX += x[i]
		sumY += y[i]
		sumXY += x[i] * y[i]
		sumX2 += x[i] * x[i]
		sumY2 += y[i] * y[i]
	}

	numerator := n*sumXY - sumX*sumY
	denominator := math.Sqrt((n*sumX2 - sumX*sumX) * (n*sumY2 - sumY*sumY))

	if denominator == 0 {
		return 0, fmt.Errorf("åˆ†æ¯ãŒ0ã«ãªã‚Šã¾ã—ãŸï¼ˆæ¨™æº–åå·®ãŒ0ï¼‰")
	}

	return numerator / denominator, nil
}

// CalculatePValue ç›¸é–¢ä¿‚æ•°ã®på€¤ã‚’è¿‘ä¼¼è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
func (s *StatisticsService) CalculatePValue(r float64, n int) float64 {
	if n < 3 {
		return 1.0 // ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã™ãã‚‹
	}

	// tçµ±è¨ˆé‡ã®è¨ˆç®—
	t := r * math.Sqrt(float64(n-2)) / math.Sqrt(1-r*r)

	// è‡ªç”±åº¦ n-2 ã®tåˆ†å¸ƒã‚’ä½¿ã£ã¦på€¤ã‚’è¿‘ä¼¼
	// ç°¡æ˜“ç‰ˆ: |t| > 2.0 ã§æœ‰æ„ï¼ˆp < 0.05ç¨‹åº¦ï¼‰
	absT := math.Abs(t)
	if absT > 2.576 {
		return 0.01 // p < 0.01
	} else if absT > 1.96 {
		return 0.05 // p < 0.05
	} else {
		return 0.10 // p > 0.05 (not significant)
	}
}

// InterpretCorrelation ç›¸é–¢ä¿‚æ•°ã‚’äººé–“ãŒèª­ã‚ã‚‹å½¢ã§è§£é‡ˆ
func (s *StatisticsService) InterpretCorrelation(r float64, pValue float64) string {
	absR := math.Abs(r)
	strength := ""

	if absR >= 0.7 {
		strength = "å¼·ã„"
	} else if absR >= 0.4 {
		strength = "ä¸­ç¨‹åº¦ã®"
	} else if absR >= 0.2 {
		strength = "å¼±ã„"
	} else {
		strength = "ã»ã¼ç„¡ã„"
	}

	direction := "æ­£ã®"
	if r < 0 {
		direction = "è² ã®"
	}

	significance := ""
	if pValue < 0.05 {
		significance = "ï¼ˆçµ±è¨ˆçš„ã«æœ‰æ„ï¼‰"
	} else {
		significance = "ï¼ˆçµ±è¨ˆçš„ã«æœ‰æ„ã§ã¯ãªã„ï¼‰"
	}

	return fmt.Sprintf("%s%sç›¸é–¢ %s", strength, direction, significance)
}

// calculateMean å¹³å‡å€¤ã‚’è¨ˆç®—
func (s *StatisticsService) calculateMean(values []float64) float64 {
	if len(values) == 0 {
		return 0
	}
	sum := 0.0
	for _, v := range values {
		sum += v
	}
	return sum / float64(len(values))
}

// calculateStandardDeviation æ¨™æº–åå·®ã‚’è¨ˆç®—
func (s *StatisticsService) calculateStandardDeviation(values []float64) float64 {
	if len(values) == 0 {
		return 0
	}
	mean := s.calculateMean(values)
	sumSquaredDiff := 0.0
	for _, v := range values {
		diff := v - mean
		sumSquaredDiff += diff * diff
	}
	variance := sumSquaredDiff / float64(len(values))
	return math.Sqrt(variance)
}

// AnalyzeSalesWeatherCorrelation è²©å£²ãƒ‡ãƒ¼ã‚¿ã¨æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã®ç›¸é–¢ã‚’åˆ†æ
func (s *StatisticsService) AnalyzeSalesWeatherCorrelation(
	salesData []models.WeatherSalesData,
	regionCode string,
) ([]models.CorrelationResult, error) {

	if len(salesData) == 0 {
		return nil, fmt.Errorf("è²©å£²ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
	}

	// è²©å£²ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ç¯„å›²ã‚’ç‰¹å®š
	var startDate, endDate time.Time
	for i, data := range salesData {
		t, err := time.Parse("2006-01-02", data.Date)
		if err != nil {
			continue
		}
		if i == 0 || t.Before(startDate) {
			startDate = t
		}
		if i == 0 || t.After(endDate) {
			endDate = t
		}
	}

	// æ—¥ä»˜ç¯„å›²ãŒç‰¹å®šã§ããªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆéå»90æ—¥ï¼‰
	if startDate.IsZero() || endDate.IsZero() {
		endDate = time.Now()
		startDate = endDate.AddDate(0, 0, -90)
	}

	// æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆè²©å£²ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“ã«åˆã‚ã›ã‚‹ï¼‰
	weatherData, err := s.weatherService.GetHistoricalWeatherData(regionCode, startDate, endDate)
	if err != nil {
		return nil, fmt.Errorf("æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—: %w", err)
	}

	// æ—¥ä»˜ã‚’ã‚­ãƒ¼ã«ã—ã¦æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ—åŒ–
	weatherMap := make(map[string]struct {
		Temperature float64
		Humidity    float64
	})
	for _, w := range weatherData {
		weatherMap[w.Date] = struct {
			Temperature float64
			Humidity    float64
		}{
			Temperature: w.Temperature,
			Humidity:    w.Humidity,
		}
	}

	// è²©å£²ãƒ‡ãƒ¼ã‚¿ã¨æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸
	var temperatures, humidities, sales []float64
	for _, sale := range salesData {
		if weather, ok := weatherMap[sale.Date]; ok {
			temperatures = append(temperatures, weather.Temperature)
			humidities = append(humidities, weather.Humidity)
			sales = append(sales, sale.Sales)
		}
	}

	if len(sales) < 3 {
		return nil, fmt.Errorf("ãƒãƒƒãƒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã¾ã™ï¼ˆæœ€ä½3ä»¶å¿…è¦ï¼‰")
	}

	var results []models.CorrelationResult

	// æ°—æ¸©ã¨å£²ä¸Šã®ç›¸é–¢
	tempCorr, err := s.CalculateCorrelation(temperatures, sales)
	if err == nil {
		pValue := s.CalculatePValue(tempCorr, len(temperatures))
		results = append(results, models.CorrelationResult{
			Factor:          "temperature",
			CorrelationCoef: tempCorr,
			PValue:          pValue,
			SampleSize:      len(temperatures),
			Interpretation:  s.InterpretCorrelation(tempCorr, pValue),
		})
	}

	// æ¹¿åº¦ã¨å£²ä¸Šã®ç›¸é–¢
	humCorr, err := s.CalculateCorrelation(humidities, sales)
	if err == nil {
		pValue := s.CalculatePValue(humCorr, len(humidities))
		results = append(results, models.CorrelationResult{
			Factor:          "humidity",
			CorrelationCoef: humCorr,
			PValue:          pValue,
			SampleSize:      len(humidities),
			Interpretation:  s.InterpretCorrelation(humCorr, pValue),
		})
	}

	return results, nil
}

// PerformLinearRegression å˜å›å¸°åˆ†æã‚’å®Ÿè¡Œ
func (s *StatisticsService) PerformLinearRegression(x, y []float64) (*models.RegressionResult, error) {
	if len(x) != len(y) || len(x) < 2 {
		return nil, fmt.Errorf("ãƒ‡ãƒ¼ã‚¿ç³»åˆ—ã®é•·ã•ãŒä¸€è‡´ã—ãªã„ã‹ã€ãƒ‡ãƒ¼ã‚¿æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
	}

	n := float64(len(x))
	var sumX, sumY, sumXY, sumX2 float64

	for i := 0; i < len(x); i++ {
		sumX += x[i]
		sumY += y[i]
		sumXY += x[i] * y[i]
		sumX2 += x[i] * x[i]
	}

	// å‚¾ãï¼ˆslopeï¼‰ã®è¨ˆç®—
	slope := (n*sumXY - sumX*sumY) / (n*sumX2 - sumX*sumX)

	// åˆ‡ç‰‡ï¼ˆinterceptï¼‰ã®è¨ˆç®—
	intercept := (sumY - slope*sumX) / n

	// RÂ²ï¼ˆæ±ºå®šä¿‚æ•°ï¼‰ã®è¨ˆç®—
	meanY := sumY / n
	var ssTotal, ssResidual float64
	for i := 0; i < len(x); i++ {
		predicted := slope*x[i] + intercept
		ssTotal += (y[i] - meanY) * (y[i] - meanY)
		ssResidual += (y[i] - predicted) * (y[i] - predicted)
	}
	rSquared := 1 - (ssResidual / ssTotal)

	// äºˆæ¸¬å€¤ã®è¨ˆç®—ï¼ˆæœ€å¾Œã®xå€¤ã‚’ä½¿ç”¨ï¼‰
	lastX := x[len(x)-1]
	prediction := slope*lastX + intercept

	// ä¿¡é ¼åº¦ã®è¨ˆç®—ï¼ˆRÂ²ã‚’ãƒ™ãƒ¼ã‚¹ã«ï¼‰
	confidence := rSquared

	description := fmt.Sprintf("å›å¸°å¼: y = %.2fx + %.2f (RÂ² = %.3f)", slope, intercept, rSquared)

	return &models.RegressionResult{
		Slope:       slope,
		Intercept:   intercept,
		RSquared:    rSquared,
		Prediction:  prediction,
		Confidence:  confidence,
		Description: description,
	}, nil
}

// GenerateStatisticalSummary çµ±è¨ˆã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
func (s *StatisticsService) GenerateStatisticalSummary(
	salesData []models.WeatherSalesData,
	regionCode string,
) (string, error) {

	if len(salesData) == 0 {
		return "", fmt.Errorf("è²©å£²ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
	}

	// åŸºæœ¬çµ±è¨ˆé‡ã®è¨ˆç®—
	var totalSales, minSales, maxSales float64
	minSales = math.MaxFloat64
	maxSales = -math.MaxFloat64

	salesByDate := make(map[string]float64)
	for _, data := range salesData {
		totalSales += data.Sales
		if data.Sales < minSales {
			minSales = data.Sales
		}
		if data.Sales > maxSales {
			maxSales = data.Sales
		}
		salesByDate[data.Date] = data.Sales
	}

	avgSales := totalSales / float64(len(salesData))

	// æ¨™æº–åå·®ã®è¨ˆç®—
	var variance float64
	for _, data := range salesData {
		diff := data.Sales - avgSales
		variance += diff * diff
	}
	stdDev := math.Sqrt(variance / float64(len(salesData)))

	// ä¸­å¤®å€¤ã®è¨ˆç®—
	sortedSales := make([]float64, len(salesData))
	for i, data := range salesData {
		sortedSales[i] = data.Sales
	}
	sort.Float64s(sortedSales)
	median := sortedSales[len(sortedSales)/2]

	summary := fmt.Sprintf(`çµ±è¨ˆã‚µãƒãƒªãƒ¼:
- ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: %d
- å¹³å‡å£²ä¸Š: %.2f
- ä¸­å¤®å€¤: %.2f
- æ¨™æº–åå·®: %.2f
- æœ€å°å€¤: %.2f
- æœ€å¤§å€¤: %.2f
- ç·å£²ä¸Š: %.2f
`,
		len(salesData),
		avgSales,
		median,
		stdDev,
		minSales,
		maxSales,
		totalSales,
	)

	return summary, nil
}

// CreateAnalysisReport ç·åˆçš„ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ
func (s *StatisticsService) CreateAnalysisReport(
	fileName string,
	salesData []models.WeatherSalesData,
	regionCode string,
	aiInsights string,
) (*models.AnalysisReport, error) {

	// ç›¸é–¢åˆ†æ
	correlations, err := s.AnalyzeSalesWeatherCorrelation(salesData, regionCode)
	if err != nil {
		correlations = []models.CorrelationResult{} // ã‚¨ãƒ©ãƒ¼ã§ã‚‚ç©ºé…åˆ—ã§ç¶™ç¶š
	}

	// çµ±è¨ˆã‚µãƒãƒªãƒ¼ç”Ÿæˆ
	summary, err := s.GenerateStatisticalSummary(salesData, regionCode)
	if err != nil {
		summary = "çµ±è¨ˆã‚µãƒãƒªãƒ¼ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
	}

	// å›å¸°åˆ†æï¼ˆæ°—æ¸©ã¨å£²ä¸Šï¼‰
	var regression *models.RegressionResult
	var weatherMatches int
	var dateRange string

	if len(salesData) > 0 {
		// è²©å£²ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ç¯„å›²ã‚’ç‰¹å®š
		var startDate, endDate time.Time
		for i, data := range salesData {
			t, err := time.Parse("2006-01-02", data.Date)
			if err != nil {
				continue
			}
			if i == 0 || t.Before(startDate) {
				startDate = t
			}
			if i == 0 || t.After(endDate) {
				endDate = t
			}
		}

		// æ—¥ä»˜ç¯„å›²ãŒç‰¹å®šã§ããªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
		if startDate.IsZero() || endDate.IsZero() {
			endDate = time.Now()
			startDate = endDate.AddDate(0, 0, -90)
		}

		dateRange = fmt.Sprintf("%s ã€œ %s", startDate.Format("2006-01-02"), endDate.Format("2006-01-02"))

		// æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
		var temps, sales []float64
		weatherData, err := s.weatherService.GetHistoricalWeatherData(regionCode, startDate, endDate)
		if err != nil {
			log.Printf("âš ï¸ æ°—è±¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: %v", err)
		} else {
			log.Printf("âœ… æ°—è±¡ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: %dä»¶ (æœŸé–“: %s ã€œ %s)", len(weatherData), startDate.Format("2006-01-02"), endDate.Format("2006-01-02"))
		}

		weatherMap := make(map[string]float64)
		for _, w := range weatherData {
			weatherMap[w.Date] = w.Temperature
		}

		log.Printf("ğŸ“Š è²©å£²ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: %d, æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒ—ã‚µã‚¤ã‚º: %d", len(salesData), len(weatherMap))

		// æ—¥ä»˜å½¢å¼ã®è¨ºæ–­ãƒ­ã‚°ã‚’è¿½åŠ 
		if len(salesData) > 0 {
			log.Printf("ğŸ” [è¨ºæ–­] è²©å£²ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ä¾‹: '%s'", salesData[0].Date)
		}
		if len(weatherData) > 0 {
			log.Printf("ğŸ” [è¨ºæ–­] æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ä¾‹: '%s'", weatherData[0].Date)
		}

		for _, sale := range salesData {
			if temp, ok := weatherMap[sale.Date]; ok {
				temps = append(temps, temp)
				sales = append(sales, sale.Sales)
				weatherMatches++
			}
		}

		log.Printf("ğŸ”— ãƒãƒƒãƒãƒ³ã‚°çµæœ: %dä»¶ / %dä»¶", weatherMatches, len(salesData))

		if len(temps) >= 2 {
			regression, _ = s.PerformLinearRegression(temps, sales)
		}
	}

	// ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
	recommendations := s.generateRecommendations(correlations, regression)

	report := &models.AnalysisReport{
		ReportID:        uuid.New().String(),
		FileName:        fileName,
		AnalysisDate:    time.Now().Format(time.RFC3339),
		DataPoints:      len(salesData),
		DateRange:       dateRange,
		WeatherMatches:  weatherMatches,
		Summary:         summary,
		Correlations:    correlations,
		Regression:      regression,
		AIInsights:      aiInsights,
		Recommendations: recommendations,
	}

	return report, nil
}

// generateRecommendations åˆ†æçµæœã«åŸºã¥ã„ã¦ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
func (s *StatisticsService) generateRecommendations(
	correlations []models.CorrelationResult,
	regression *models.RegressionResult,
) []string {
	var recommendations []string

	// ç›¸é–¢åˆ†æã‹ã‚‰ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
	for _, corr := range correlations {
		if math.Abs(corr.CorrelationCoef) > 0.5 && corr.PValue < 0.05 {
			if corr.Factor == "temperature" {
				if corr.CorrelationCoef > 0 {
					recommendations = append(recommendations, "æ°—æ¸©ãŒé«˜ã„ã»ã©å£²ä¸ŠãŒå¢—åŠ ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚å¤å­£ã®åœ¨åº«ã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
				} else {
					recommendations = append(recommendations, "æ°—æ¸©ãŒä½ã„ã»ã©å£²ä¸ŠãŒå¢—åŠ ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚å†¬å­£ã®åœ¨åº«ã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
				}
			}
			if corr.Factor == "humidity" {
				recommendations = append(recommendations, "æ¹¿åº¦ã¨å£²ä¸Šã«æœ‰æ„ãªç›¸é–¢ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚å¤©æ°—äºˆå ±ã¨é€£å‹•ã—ãŸåœ¨åº«ç®¡ç†ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
			}
		}
	}

	// å›å¸°åˆ†æã‹ã‚‰ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
	if regression != nil && regression.RSquared > 0.3 {
		recommendations = append(recommendations, fmt.Sprintf("å›å¸°ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã¯%.1f%%ã§ã™ã€‚æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸéœ€è¦äºˆæ¸¬ãŒæœ‰åŠ¹ã§ã™ã€‚", regression.RSquared*100))
	}

	// ç›¸é–¢ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆ
	if len(correlations) == 0 {
		recommendations = append(recommendations, "âš ï¸ è²©å£²ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ã¨æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãŒãƒãƒƒãƒã—ã¾ã›ã‚“ã§ã—ãŸã€‚æ—¥ä»˜å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆYYYY-MM-DDå½¢å¼ã‚’æ¨å¥¨ï¼‰ã€‚")
		recommendations = append(recommendations, "ç¾åœ¨ã®æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã¯æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ï¼ˆéå»3å¹´åˆ†ï¼‰ã§ã™ã€‚å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿æœŸé–“ã¨ã®æ•´åˆæ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
	}

	// ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
	if len(recommendations) == 0 {
		recommendations = append(recommendations, "ã•ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿è“„ç©ã«ã‚ˆã‚Šã€ã‚ˆã‚Šç²¾åº¦ã®é«˜ã„åˆ†æãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚")
		recommendations = append(recommendations, "å­£ç¯€æ€§ã‚„æ›œæ—¥åŠ¹æœã‚‚è€ƒæ…®ã—ãŸå¤šå¤‰é‡è§£æã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
	}

	return recommendations
}

// PredictFutureSales å°†æ¥ã®å£²ä¸Šã‚’äºˆæ¸¬ã™ã‚‹
func (s *StatisticsService) PredictFutureSales(
	historicalSales []float64,
	historicalTemperatures []float64,
	futureTemperature float64,
	confidenceLevel float64,
) (models.SalesPrediction, error) {
	if len(historicalSales) != len(historicalTemperatures) {
		return models.SalesPrediction{}, fmt.Errorf("ãƒ‡ãƒ¼ã‚¿ç³»åˆ—ã®é•·ã•ãŒä¸€è‡´ã—ã¾ã›ã‚“")
	}

	if len(historicalSales) < 10 {
		return models.SalesPrediction{}, fmt.Errorf("äºˆæ¸¬ã«ã¯æœ€ä½10ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
	}

	// 1. å›å¸°åˆ†æã§äºˆæ¸¬å€¤ã‚’è¨ˆç®—
	regression, err := s.PerformLinearRegression(historicalTemperatures, historicalSales)
	if err != nil {
		return models.SalesPrediction{}, err
	}

	predictedValue := regression.Slope*futureTemperature + regression.Intercept

	// 2. æ®‹å·®ã®æ¨™æº–åå·®ã‚’è¨ˆç®—ï¼ˆäºˆæ¸¬ã®ä¸ç¢ºå®Ÿæ€§ï¼‰
	var residuals []float64
	for i := 0; i < len(historicalSales); i++ {
		predicted := regression.Slope*historicalTemperatures[i] + regression.Intercept
		residual := historicalSales[i] - predicted
		residuals = append(residuals, residual)
	}

	residualStdDev := s.calculateStandardDeviation(residuals)

	// 3. ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ95%ï¼‰
	if confidenceLevel == 0 {
		confidenceLevel = 0.95
	}

	// zå€¤ï¼ˆæ­£è¦åˆ†å¸ƒï¼‰: 90%=1.645, 95%=1.96, 99%=2.576
	var zScore float64
	switch confidenceLevel {
	case 0.90:
		zScore = 1.645
	case 0.95:
		zScore = 1.96
	case 0.99:
		zScore = 2.576
	default:
		zScore = 1.96 // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ95%
	}

	margin := zScore * residualStdDev
	lowerBound := predictedValue - margin
	upperBound := predictedValue + margin

	// 4. äºˆæ¸¬ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—ï¼ˆRÂ²å€¤ãƒ™ãƒ¼ã‚¹ï¼‰
	confidence := regression.RSquared

	// 5. äºˆæ¸¬æ ¹æ‹ ã‚’ç”Ÿæˆ
	factors := []string{
		fmt.Sprintf("æ°—æ¸© %.1fÂ°C ã«åŸºã¥ãå›å¸°äºˆæ¸¬", futureTemperature),
		fmt.Sprintf("éå» %d ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’", len(historicalSales)),
		fmt.Sprintf("æ±ºå®šä¿‚æ•° RÂ² = %.3f", regression.RSquared),
	}

	if regression.RSquared > 0.5 {
		factors = append(factors, "æ°—æ¸©ã¨å£²ä¸Šã®ç›¸é–¢ãŒå¼·ã„ãŸã‚ã€äºˆæ¸¬ç²¾åº¦ã¯é«˜ã„ã§ã™")
	} else if regression.RSquared > 0.3 {
		factors = append(factors, "æ°—æ¸©ã¨å£²ä¸Šã«ç›¸é–¢ãŒã‚ã‚Šã¾ã™ãŒã€ä»–ã®è¦å› ã‚‚è€ƒæ…®ãŒå¿…è¦ã§ã™")
	} else {
		factors = append(factors, "æ°—æ¸©ä»¥å¤–ã®è¦å› ãŒå£²ä¸Šã«å¤§ããå½±éŸ¿ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
	}

	return models.SalesPrediction{
		PredictedValue: predictedValue,
		ConfidenceInterval: models.ConfidenceInterval{
			Lower:      lowerBound,
			Upper:      upperBound,
			Confidence: confidenceLevel,
		},
		Confidence:         confidence,
		PredictionFactors:  factors,
		RegressionEquation: fmt.Sprintf("y = %.2fx + %.2f", regression.Slope, regression.Intercept),
	}, nil
}

// DetectAnomalies å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç•°å¸¸å€¤ã‚’æ¤œå‡ºã™ã‚‹ï¼ˆç§»å‹•å¹³å‡ä¹–é›¢ç‡æ³•ï¼‰
// granularity: "daily", "weekly", "monthly" - ãƒ‡ãƒ¼ã‚¿é›†ç´„ç²’åº¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "weekly"ï¼‰
func (s *StatisticsService) DetectAnomalies(sales []float64, dates []string, productID string, productName string) []models.AnomalyDetection {
	return s.DetectAnomaliesWithGranularity(sales, dates, productID, productName, "weekly")
}

// DetectAnomaliesWithGranularity ç²’åº¦ã‚’æŒ‡å®šã—ã¦ç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿè¡Œ
func (s *StatisticsService) DetectAnomaliesWithGranularity(sales []float64, dates []string, productID string, productName string, granularity string) []models.AnomalyDetection {
	displayName := productName
	if displayName == "" {
		displayName = productID
	}

	// ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯é€±æ¬¡
	if granularity == "" {
		granularity = "weekly"
	}

	log.Printf("[ç•°å¸¸æ¤œçŸ¥@%s] ç²’åº¦: %s ã§ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„ã—ã¦ã‹ã‚‰ç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿè¡Œã—ã¾ã™", displayName, granularity)

	// æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã®ã¿é›†ç´„ãŒå¿…è¦ï¼ˆé€±æ¬¡ãƒ»æœˆæ¬¡ã®å ´åˆã¯æ—¢ã«é›†ç´„æ¸ˆã¿ã¨ä»®å®šï¼‰
	aggregatedSales := sales
	aggregatedDates := dates

	if granularity != "daily" && len(sales) > 0 {
		// ãƒ‡ãƒ¼ã‚¿ã‚’é€±æ¬¡ã¾ãŸã¯æœˆæ¬¡ã«é›†ç´„
		aggregatedSales, aggregatedDates = s.aggregateDataForAnomalyDetection(sales, dates, granularity)
		log.Printf("[ç•°å¸¸æ¤œçŸ¥@%s] ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„: %dä»¶ â†’ %dä»¶", displayName, len(sales), len(aggregatedSales))
	}

	// ç§»å‹•å¹³å‡ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’ç²’åº¦ã«å¿œã˜ã¦èª¿æ•´
	var windowSize int
	var percentageThreshold float64

	switch granularity {
	case "daily":
		windowSize = 30           // 30æ—¥é–“ã®ç§»å‹•å¹³å‡
		percentageThreshold = 0.5 // 50%ã®ä¹–é›¢
	case "weekly":
		windowSize = 4            // 4é€±é–“ã®ç§»å‹•å¹³å‡
		percentageThreshold = 0.4 // 40%ã®ä¹–é›¢ï¼ˆé€±æ¬¡ã¯å¤‰å‹•ãŒå¤§ãã„ãŸã‚ç·©å’Œï¼‰
	case "monthly":
		windowSize = 3            // 3ãƒ¶æœˆã®ç§»å‹•å¹³å‡
		percentageThreshold = 0.3 // 30%ã®ä¹–é›¢ï¼ˆæœˆæ¬¡ã¯ã•ã‚‰ã«ç·©å’Œï¼‰
	default:
		windowSize = 4
		percentageThreshold = 0.4
	}

	if len(aggregatedSales) < windowSize {
		log.Printf("[ç•°å¸¸æ¤œçŸ¥@%s] ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªãã€ç§»å‹•å¹³å‡ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆ%dä»¶ < %dä»¶ï¼‰", displayName, len(aggregatedSales), windowSize)
		return []models.AnomalyDetection{}
	}

	var anomalies []models.AnomalyDetection

	for i := windowSize; i < len(aggregatedSales); i++ {
		// ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
		window := aggregatedSales[i-windowSize : i]

		// ç§»å‹•å¹³å‡ã‚’è¨ˆç®—
		mean := s.calculateMean(window)

		// ç¾åœ¨ã®å€¤
		currentValue := aggregatedSales[i]

		// ç§»å‹•å¹³å‡ã‹ã‚‰ã®ä¹–é›¢ã‚’è¨ˆç®—
		deviation := currentValue - mean

		// é–¾å€¤ã‚’è¨ˆç®—
		threshold := mean * percentageThreshold

		if mean > 0 && math.Abs(deviation) > threshold {
			anomalyType := "æ€¥å¢—"
			if deviation < 0 {
				anomalyType = "æ€¥æ¸›"
			}

			// Zã‚¹ã‚³ã‚¢ã¯å‚è€ƒå€¤ã¨ã—ã¦ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã®çµ±è¨ˆã§è¨ˆç®—ï¼‰
			stdDev := s.calculateStandardDeviation(window)
			var zScore float64
			if stdDev > 0 {
				zScore = deviation / stdDev
			}

			anomalies = append(anomalies, models.AnomalyDetection{
				Date:          aggregatedDates[i],
				ProductID:     productID,
				ProductName:   productName,
				ActualValue:   currentValue,
				ExpectedValue: mean, // æœŸå¾…å€¤ã¨ã—ã¦ç§»å‹•å¹³å‡ã‚’ä½¿ç”¨
				Deviation:     math.Abs(deviation),
				ZScore:        zScore,
				AnomalyType:   anomalyType,
				Severity:      s.calculateSeverity(math.Abs(zScore)),
			})
		}
	}

	log.Printf("[ç•°å¸¸æ¤œçŸ¥@%s] ç§»å‹•å¹³å‡æ³•ã«ã‚ˆã‚Š %d ä»¶ã®ç•°å¸¸ã‚’æ¤œå‡ºã—ã¾ã—ãŸ", displayName, len(anomalies))

	return anomalies
}

// aggregateDataForAnomalyDetection ç•°å¸¸æ¤œçŸ¥ç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„
func (s *StatisticsService) aggregateDataForAnomalyDetection(sales []float64, dates []string, granularity string) ([]float64, []string) {
	if len(sales) != len(dates) {
		log.Printf("[è­¦å‘Š] sales ã¨ dates ã®é•·ã•ãŒä¸€è‡´ã—ã¾ã›ã‚“: %d != %d", len(sales), len(dates))
		return sales, dates
	}

	// æœŸé–“ã‚­ãƒ¼ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„
	periodMap := make(map[string][]float64)
	periodOrder := []string{} // é †åºã‚’ä¿æŒ

	for i, dateStr := range dates {
		t, err := time.Parse("2006-01-02", dateStr)
		if err != nil {
			log.Printf("[è­¦å‘Š] æ—¥ä»˜ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—: %s", dateStr)
			continue
		}

		var periodKey string
		switch granularity {
		case "weekly":
			// æœˆæ›œå§‹ã¾ã‚Šã®é€±ç•ªå·
			year, week := t.ISOWeek()
			periodKey = fmt.Sprintf("%d-W%02d", year, week)
		case "monthly":
			periodKey = t.Format("2006-01")
		default:
			periodKey = dateStr // æ—¥æ¬¡ã®å ´åˆã¯ãã®ã¾ã¾
		}

		if _, exists := periodMap[periodKey]; !exists {
			periodOrder = append(periodOrder, periodKey)
		}
		periodMap[periodKey] = append(periodMap[periodKey], sales[i])
	}

	// é›†ç´„ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
	aggregatedSales := make([]float64, 0, len(periodOrder))
	aggregatedDates := make([]string, 0, len(periodOrder))

	for _, periodKey := range periodOrder {
		values := periodMap[periodKey]
		
		// åˆè¨ˆã‚’è¨ˆç®—
		var total float64
		for _, v := range values {
			total += v
		}

		aggregatedSales = append(aggregatedSales, total)
		aggregatedDates = append(aggregatedDates, periodKey)
	}

	return aggregatedSales, aggregatedDates
}

// calculateSeverity ç•°å¸¸ã®æ·±åˆ»åº¦ã‚’è¨ˆç®—
func (s *StatisticsService) calculateSeverity(absZScore float64) string {
	if absZScore > 4.0 {
		return "critical" // æ¥µã‚ã¦ç•°å¸¸
	} else if absZScore > 3.5 {
		return "high" // é«˜åº¦ãªç•°å¸¸
	} else if absZScore > 3.0 {
		return "medium" // ä¸­ç¨‹åº¦ã®ç•°å¸¸
	}
	return "low"
}

// formatDateForDisplay æ—¥ä»˜ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
// ä¾‹: "2022-04" â†’ "2022å¹´4æœˆ"
//     "2022-W10" â†’ "2022å¹´ ç¬¬10é€±"
//     "2022-03-07" â†’ "2022å¹´3æœˆ7æ—¥"
func (s *StatisticsService) formatDateForDisplay(date string) string {
	// æœˆæ¬¡å½¢å¼: YYYY-MM
	if len(date) == 7 && date[4] == '-' {
		t, err := time.Parse("2006-01", date)
		if err == nil {
			return t.Format("2006å¹´1æœˆ")
		}
	}
	
	// é€±æ¬¡å½¢å¼: YYYY-WWW
	if len(date) >= 7 && strings.Contains(date, "-W") {
		parts := strings.Split(date, "-W")
		if len(parts) == 2 {
			return fmt.Sprintf("%så¹´ ç¬¬%sé€±", parts[0], parts[1])
		}
	}
	
	// æ—¥æ¬¡å½¢å¼: YYYY-MM-DD
	if len(date) == 10 {
		t, err := time.Parse("2006-01-02", date)
		if err == nil {
			return t.Format("2006å¹´1æœˆ2æ—¥")
		}
	}
	
	// ãƒ‘ãƒ¼ã‚¹ã§ããªã„å ´åˆã¯ãã®ã¾ã¾è¿”ã™
	return date
}

// GenerateAIQuestion ç•°å¸¸å€¤ã«åŸºã¥ã„ã¦AIãŒè³ªå•ã‚’ç”Ÿæˆ
func (s *StatisticsService) GenerateAIQuestion(anomaly models.AnomalyDetection) (string, []string) {
	// è£½å“ã®è¡¨ç¤ºåã‚’æ±ºå®šï¼ˆè£½å“åãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°IDï¼‰
	displayName := anomaly.ProductName
	if displayName == "" {
		displayName = anomaly.ProductID
	}
	
	// æ—¥ä»˜ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
	formattedDate := s.formatDateForDisplay(anomaly.Date)
	
	// AIã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ã€AIã«è³ªå•ã¨é¸æŠè‚¢ã‚’ç”Ÿæˆã•ã›ã‚‹
	if s.azureOpenAIService != nil {
		// AnomalyDetectionã‚’Anomalyã«å¤‰æ›ï¼ˆå¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿ï¼‰
		anomalyForAI := models.Anomaly{
			Date:        formattedDate, // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ã®æ—¥ä»˜ã‚’ä½¿ç”¨
			ProductID:   displayName,    // è¡¨ç¤ºåã‚’ä½¿ç”¨
			Description: fmt.Sprintf("å£²ä¸Š%s (å®Ÿç¸¾: %.0f, æœŸå¾…å€¤: %.0f)", anomaly.AnomalyType, anomaly.ActualValue, anomaly.ExpectedValue),
		}

		result, err := s.azureOpenAIService.GenerateQuestionAndChoicesFromAnomaly(anomalyForAI)
		if err == nil && result != nil && result.Question != "" {
			return result.Question, result.Choices
		}
		log.Printf("âš ï¸ AIã‹ã‚‰ã®è³ªå•ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚ã‚¨ãƒ©ãƒ¼: %v", err)
	}

	// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®è³ªå•ã¨å›ºå®šã®é¸æŠè‚¢
	var question string
	if anomaly.AnomalyType == "æ€¥å¢—" {
		question = fmt.Sprintf(
			"ğŸ“ˆ %s ã«ã€Œ%sã€ã®å£²ä¸ŠãŒé€šå¸¸ã‚ˆã‚Š %.0f å¢—åŠ ã—ã¾ã—ãŸï¼ˆæœŸå¾…å€¤: %.0f â†’ å®Ÿç¸¾: %.0fï¼‰ã€‚ã“ã®æ™‚æœŸã«ç‰¹åˆ¥ãªã‚¤ãƒ™ãƒ³ãƒˆã€ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã€ã¾ãŸã¯å¤–çš„è¦å› ã¯ã‚ã‚Šã¾ã—ãŸã‹ï¼Ÿ",
			formattedDate,
			displayName,
			anomaly.Deviation,
			anomaly.ExpectedValue,
			anomaly.ActualValue,
		)
	} else {
		question = fmt.Sprintf(
			"ğŸ“‰ %s ã«ã€Œ%sã€ã®å£²ä¸ŠãŒé€šå¸¸ã‚ˆã‚Š %.0f æ¸›å°‘ã—ã¾ã—ãŸï¼ˆæœŸå¾…å€¤: %.0f â†’ å®Ÿç¸¾: %.0fï¼‰ã€‚ã“ã®æ™‚æœŸã«å£²ä¸Šæ¸›å°‘ã®åŸå› ã¨ãªã£ãŸè¦å› ï¼ˆå¤©å€™ã€ç«¶åˆã€åœ¨åº«åˆ‡ã‚Œãªã©ï¼‰ã¯ã‚ã‚Šã¾ã—ãŸã‹ï¼Ÿ",
			formattedDate,
			displayName,
			anomaly.Deviation,
			anomaly.ExpectedValue,
			anomaly.ActualValue,
		)
	}

	defaultChoices := []string{
		"ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ»è²©ä¿ƒæ´»å‹•",
		"å¤©å€™ã®å½±éŸ¿",
		"ç«¶åˆä»–ç¤¾ã®å‹•ã",
		"ç‰¹ã«æ€ã„å½“ãŸã‚‹ç¯€ã¯ãªã„",
		"ãã®ä»–ï¼ˆè‡ªç”±è¨˜è¿°ï¼‰",
	}

	return question, defaultChoices
}

// ForecastProductDemand è£½å“åˆ¥ã®éœ€è¦äºˆæ¸¬ã‚’å®Ÿè¡Œ
func (s *StatisticsService) ForecastProductDemand(
	productID string,
	productName string,
	historicalData []models.SalesDataPoint,
	period string,
	regionCode string,
) (models.ProductForecast, error) {
	if len(historicalData) < 14 {
		return models.ProductForecast{}, fmt.Errorf("äºˆæ¸¬ã«ã¯æœ€ä½14æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
	}

	// æœŸé–“ã®æ—¥æ•°ã‚’æ±ºå®š
	var forecastDays int
	switch period {
	case "week":
		forecastDays = 7
	case "2weeks":
		forecastDays = 14
	case "month":
		forecastDays = 30
	default:
		forecastDays = 7
	}

	// çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
	stats := s.calculateProductStatistics(historicalData)

	// æ›œæ—¥åŠ¹æœã‚’è¨ˆç®—
	weekdayEffect := s.calculateWeekdayEffect(historicalData)

	// æ°—æ¸©ã¨ã®ç›¸é–¢ã‚’è¨ˆç®—
	var temperatures, sales []float64
	for _, point := range historicalData {
		if point.Temperature > 0 {
			temperatures = append(temperatures, point.Temperature)
			sales = append(sales, point.Sales)
		}
	}

	var regression *models.RegressionResult
	var err error
	if len(temperatures) >= 10 {
		regression, err = s.PerformLinearRegression(temperatures, sales)
		if err != nil {
			log.Printf("å›å¸°åˆ†æã‚¨ãƒ©ãƒ¼: %v", err)
		}
	}

	// å°†æ¥ã®äºˆæ¸¬æ—¥ã‚’ç”Ÿæˆ
	lastDate, _ := time.Parse("2006-01-02", historicalData[len(historicalData)-1].Date)
	var dailyForecasts []models.DailyForecast
	var totalForecast float64

	for i := 1; i <= forecastDays; i++ {
		forecastDate := lastDate.AddDate(0, 0, i)
		dayOfWeek := s.getDayOfWeekJP(forecastDate.Weekday())

		// åŸºæº–å€¤: å…¨ä½“å¹³å‡
		baseValue := stats.Mean

		// æ›œæ—¥åŠ¹æœã‚’é©ç”¨
		if effect, ok := weekdayEffect[dayOfWeek]; ok {
			baseValue = baseValue * effect
		}

		// æ°—æ¸©åŠ¹æœã‚’é©ç”¨ï¼ˆå›å¸°ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆï¼‰
		if regression != nil && regression.RSquared > 0.1 {
			// ç°¡æ˜“çš„ã«å­£ç¯€ã®å¹³å‡æ°—æ¸©ã‚’ä½¿ç”¨
			seasonalTemp := s.getSeasonalTemperature(forecastDate.Month())
			tempAdjustment := regression.Slope * (seasonalTemp - s.calculateMean(temperatures))
			baseValue += tempAdjustment
		}

		// ãƒˆãƒ¬ãƒ³ãƒ‰åŠ¹æœï¼ˆå˜ç´”ç§»å‹•å¹³å‡ã®å‚¾ãï¼‰
		trendAdjustment := s.calculateTrend(historicalData) * float64(i)
		baseValue += trendAdjustment

		dailyForecasts = append(dailyForecasts, models.DailyForecast{
			Date:           forecastDate.Format("2006-01-02"),
			DayOfWeek:      dayOfWeek,
			PredictedValue: math.Max(0, baseValue), // è² ã®å€¤ã‚’é¿ã‘ã‚‹
			Temperature:    s.getSeasonalTemperature(forecastDate.Month()),
		})

		totalForecast += baseValue
	}

	// ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—
	stdDev := stats.StdDev
	zScore := 1.96 // 95% confidence
	marginTotal := zScore * stdDev * math.Sqrt(float64(forecastDays))

	confidence := 0.5 // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
	if regression != nil {
		confidence = regression.RSquared
	}

	// æœŸé–“ã®ç¯„å›²ã‚’æ–‡å­—åˆ—åŒ–
	startForecast := dailyForecasts[0].Date
	endForecast := dailyForecasts[len(dailyForecasts)-1].Date
	forecastPeriod := fmt.Sprintf("%s ã€œ %s", startForecast, endForecast)

	// æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
	recommendations := s.generateForecastRecommendations(totalForecast, stats, period)

	// å­£ç¯€æ€§ã®åˆ¤å®š
	seasonality := s.detectSeasonality(historicalData)

	return models.ProductForecast{
		ProductID:      productID,
		ProductName:    productName,
		ForecastPeriod: forecastPeriod,
		PredictedTotal: math.Max(0, totalForecast),
		DailyAverage:   math.Max(0, totalForecast/float64(forecastDays)),
		ConfidenceInterval: models.ConfidenceInterval{
			Lower:      math.Max(0, totalForecast-marginTotal),
			Upper:      totalForecast + marginTotal,
			Confidence: 0.95,
		},
		Confidence:      confidence,
		DailyBreakdown:  dailyForecasts,
		Factors:         s.buildFactorsList(regression, weekdayEffect, stats),
		Seasonality:     seasonality,
		Recommendations: recommendations,
	}, nil
}

// calculateProductStatistics è£½å“ã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
func (s *StatisticsService) calculateProductStatistics(data []models.SalesDataPoint) models.ProductStatistics {
	var sales []float64
	weekdaySales := make(map[string][]float64)
	monthlySales := make(map[string][]float64)

	for _, point := range data {
		sales = append(sales, point.Sales)
		if point.DayOfWeek != "" {
			weekdaySales[point.DayOfWeek] = append(weekdaySales[point.DayOfWeek], point.Sales)
		}
		if t, err := time.Parse("2006-01-02", point.Date); err == nil {
			month := fmt.Sprintf("%dæœˆ", int(t.Month()))
			monthlySales[month] = append(monthlySales[month], point.Sales)
		}
	}

	mean := s.calculateMean(sales)
	stdDev := s.calculateStandardDeviation(sales)

	// æ›œæ—¥åˆ¥å¹³å‡
	weekdayAvg := make(map[string]float64)
	for day, values := range weekdaySales {
		weekdayAvg[day] = s.calculateMean(values)
	}

	// æœˆåˆ¥å¹³å‡
	monthlyAvg := make(map[string]float64)
	for month, values := range monthlySales {
		monthlyAvg[month] = s.calculateMean(values)
	}

	// ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘ã‚’åˆ¤å®š
	trend := s.calculateTrend(data)
	var trendDirection string
	if trend > 0.5 {
		trendDirection = "å¢—åŠ "
	} else if trend < -0.5 {
		trendDirection = "æ¸›å°‘"
	} else {
		trendDirection = "å®‰å®š"
	}

	sortedSales := make([]float64, len(sales))
	copy(sortedSales, sales)
	sort.Float64s(sortedSales)

	median := sortedSales[len(sortedSales)/2]
	min := sortedSales[0]
	max := sortedSales[len(sortedSales)-1]

	return models.ProductStatistics{
		Mean:           mean,
		Median:         median,
		StdDev:         stdDev,
		Min:            min,
		Max:            max,
		WeekdayAverage: weekdayAvg,
		MonthlyAverage: monthlyAvg,
		TrendDirection: trendDirection,
	}
}

// calculateWeekdayEffect æ›œæ—¥åŠ¹æœã‚’è¨ˆç®—ï¼ˆå…¨ä½“å¹³å‡ã«å¯¾ã™ã‚‹æ¯”ç‡ï¼‰
func (s *StatisticsService) calculateWeekdayEffect(data []models.SalesDataPoint) map[string]float64 {
	weekdaySales := make(map[string][]float64)
	var allSales []float64

	for _, point := range data {
		allSales = append(allSales, point.Sales)
		if point.DayOfWeek != "" {
			weekdaySales[point.DayOfWeek] = append(weekdaySales[point.DayOfWeek], point.Sales)
		}
	}

	overallMean := s.calculateMean(allSales)
	effect := make(map[string]float64)

	for day, sales := range weekdaySales {
		dayMean := s.calculateMean(sales)
		effect[day] = dayMean / overallMean // 1.0ãŒå¹³å‡ã€>1.0ãŒå¹³å‡ä»¥ä¸Š
	}

	return effect
}

// calculateTrend å˜ç´”ãªãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¨ˆç®—ï¼ˆ1æ—¥ã‚ãŸã‚Šã®å¤‰åŒ–é‡ï¼‰
func (s *StatisticsService) calculateTrend(data []models.SalesDataPoint) float64 {
	if len(data) < 2 {
		return 0
	}

	// æœ€åˆã®1/3ã¨æœ€å¾Œã®1/3ã®å¹³å‡ã‚’æ¯”è¼ƒ
	n := len(data)
	firstThird := n / 3
	var earlySum, lateSum float64

	for i := 0; i < firstThird; i++ {
		earlySum += data[i].Sales
	}
	for i := n - firstThird; i < n; i++ {
		lateSum += data[i].Sales
	}

	earlyAvg := earlySum / float64(firstThird)
	lateAvg := lateSum / float64(firstThird)

	// 1æ—¥ã‚ãŸã‚Šã®å¤‰åŒ–é‡
	return (lateAvg - earlyAvg) / float64(n-firstThird)
}

// getSeasonalTemperature æœˆã”ã¨ã®å¹³å‡æ°—æ¸©ã‚’è¿”ã™ï¼ˆç°¡æ˜“ç‰ˆï¼‰
func (s *StatisticsService) getSeasonalTemperature(month time.Month) float64 {
	temps := map[time.Month]float64{
		time.January:   5.0,
		time.February:  6.0,
		time.March:     10.0,
		time.April:     15.0,
		time.May:       20.0,
		time.June:      24.0,
		time.July:      28.0,
		time.August:    29.0,
		time.September: 25.0,
		time.October:   19.0,
		time.November:  13.0,
		time.December:  7.0,
	}
	return temps[month]
}

// getDayOfWeekJP æ›œæ—¥ã‚’æ—¥æœ¬èªã§è¿”ã™
func (s *StatisticsService) getDayOfWeekJP(weekday time.Weekday) string {
	days := []string{"æ—¥", "æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ"}
	return days[int(weekday)]
}

// detectSeasonality å­£ç¯€æ€§ã‚’æ¤œå‡º
func (s *StatisticsService) detectSeasonality(data []models.SalesDataPoint) string {
	if len(data) < 30 {
		return ""
	}

	monthlySales := make(map[int][]float64)
	for _, point := range data {
		if t, err := time.Parse("2006-01-02", point.Date); err == nil {
			month := int(t.Month())
			monthlySales[month] = append(monthlySales[month], point.Sales)
		}
	}

	// å¤å­£(6-8æœˆ)ã¨å†¬å­£(12-2æœˆ)ã®å¹³å‡ã‚’æ¯”è¼ƒ
	var summerSum, winterSum float64
	var summerCount, winterCount int

	for month, sales := range monthlySales {
		avg := s.calculateMean(sales)
		if month >= 6 && month <= 8 {
			summerSum += avg
			summerCount++
		} else if month == 12 || month <= 2 {
			winterSum += avg
			winterCount++
		}
	}

	if summerCount > 0 && winterCount > 0 {
		summerAvg := summerSum / float64(summerCount)
		winterAvg := winterSum / float64(winterCount)

		diff := (summerAvg - winterAvg) / winterAvg * 100
		if diff > 20 {
			return fmt.Sprintf("å¤å­£éœ€è¦ãŒé«˜ã„å‚¾å‘ï¼ˆå†¬å­£æ¯” +%.0f%%ï¼‰", diff)
		} else if diff < -20 {
			return fmt.Sprintf("å†¬å­£éœ€è¦ãŒé«˜ã„å‚¾å‘ï¼ˆå¤å­£æ¯” +%.0f%%ï¼‰", -diff)
		}
	}

	return "æ˜ç¢ºãªå­£ç¯€æ€§ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
}

// generateForecastRecommendations äºˆæ¸¬ã«åŸºã¥ãæ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
func (s *StatisticsService) generateForecastRecommendations(forecast float64, stats models.ProductStatistics, period string) []string {
	var recommendations []string

	// éœ€è¦ãƒ¬ãƒ™ãƒ«ã«åŸºã¥ãæ¨å¥¨
	if forecast > stats.Mean*1.2 {
		recommendations = append(recommendations, fmt.Sprintf("äºˆæ¸¬éœ€è¦ãŒå¹³å‡ã‚ˆã‚Šé«˜ã„ã§ã™ã€‚ååˆ†ãªåœ¨åº«ã‚’ç¢ºä¿ã—ã¦ãã ã•ã„ï¼ˆäºˆæ¸¬: %.0f, å¹³å‡: %.0fï¼‰", forecast, stats.Mean))
	} else if forecast < stats.Mean*0.8 {
		recommendations = append(recommendations, "äºˆæ¸¬éœ€è¦ãŒå¹³å‡ã‚ˆã‚Šä½ã„ã§ã™ã€‚éå‰°åœ¨åº«ã«æ³¨æ„ã—ã¦ãã ã•ã„")
	}

	// æ›œæ—¥åŠ¹æœã«åŸºã¥ãæ¨å¥¨
	if len(stats.WeekdayAverage) > 0 {
		var maxDay string
		var maxValue float64
		for day, avg := range stats.WeekdayAverage {
			if avg > maxValue {
				maxValue = avg
				maxDay = day
			}
		}
		if maxDay != "" {
			recommendations = append(recommendations, fmt.Sprintf("%sæ›œæ—¥ã®éœ€è¦ãŒæœ€ã‚‚é«˜ã„å‚¾å‘ãŒã‚ã‚Šã¾ã™", maxDay))
		}
	}

	// ãƒˆãƒ¬ãƒ³ãƒ‰ã«åŸºã¥ãæ¨å¥¨
	switch stats.TrendDirection {
	case "å¢—åŠ ":
		recommendations = append(recommendations, "éœ€è¦å¢—åŠ ãƒˆãƒ¬ãƒ³ãƒ‰ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚ä¾›çµ¦ä½“åˆ¶ã®å¼·åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
	case "æ¸›å°‘":
		recommendations = append(recommendations, "éœ€è¦æ¸›å°‘ãƒˆãƒ¬ãƒ³ãƒ‰ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ–½ç­–ã®è¦‹ç›´ã—ã‚’æ¨å¥¨ã—ã¾ã™")
	}

	return recommendations
}

// buildFactorsList äºˆæ¸¬ã«ä½¿ç”¨ã—ãŸè¦å› ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ
func (s *StatisticsService) buildFactorsList(regression *models.RegressionResult, weekdayEffect map[string]float64, stats models.ProductStatistics) []string {
	factors := []string{
		fmt.Sprintf("éå»ã®è²©å£²å®Ÿç¸¾ï¼ˆå¹³å‡: %.0få€‹/æ—¥ï¼‰", stats.Mean),
		fmt.Sprintf("ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘: %s", stats.TrendDirection),
	}

	if len(weekdayEffect) > 0 {
		factors = append(factors, "æ›œæ—¥ã«ã‚ˆã‚‹éœ€è¦å¤‰å‹•ã‚’è€ƒæ…®")
	}

	if regression != nil && regression.RSquared > 0.1 {
		factors = append(factors, fmt.Sprintf("æ°—æ¸©ã¨ã®ç›¸é–¢ï¼ˆRÂ² = %.2fï¼‰", regression.RSquared))
	}

	factors = append(factors, "å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ")

	return factors
}

// AnalyzeWeeklySales é€±æ¬¡å˜ä½ã§ã®è²©å£²åˆ†æï¼ˆç²’åº¦æŒ‡å®šå¯èƒ½ï¼‰
func (s *StatisticsService) AnalyzeWeeklySales(productID, productName string, salesData []models.SalesDataPoint, startDate, endDate time.Time, granularity string) (*models.WeeklyAnalysisResponse, error) {
	if len(salesData) == 0 {
		return nil, fmt.Errorf("è²©å£²ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
	}

	// ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯é€±æ¬¡
	if granularity == "" {
		granularity = "weekly"
	}

	var weeklySummaries []models.WeeklySummary

	switch granularity {
	case "daily":
		// æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ï¼ˆé›†ç´„ãªã—ï¼‰
		weeklySummaries = s.groupByDay(salesData)
	case "monthly":
		// æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿
		weeklySummaries = s.groupByMonth(salesData, startDate)
	default: // "weekly"
		// ãƒ‡ãƒ¼ã‚¿ã‚’é€±å˜ä½ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
		weeklyGroups := s.groupByWeek(salesData, startDate)

		// é€±ã”ã¨ã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
		weeklySummaries = make([]models.WeeklySummary, 0)
		var prevWeekSales float64 = 0

		for weekNum := 0; weekNum < len(weeklyGroups); weekNum++ {
			weekData, exists := weeklyGroups[weekNum]
			if !exists {
				continue
			}
			summary := s.calculateWeeklySummary(weekNum, weekData, prevWeekSales)
			weeklySummaries = append(weeklySummaries, summary)
			prevWeekSales = summary.TotalSales
		}
	}

	// å…¨ä½“çµ±è¨ˆã‚’è¨ˆç®—
	overallStats := s.calculateWeeklyOverallStats(weeklySummaries)

	// ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
	trends := s.analyzeWeeklyTrends(weeklySummaries)

	// æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
	recommendations := s.generateWeeklyRecommendations(weeklySummaries, overallStats, trends)

	return &models.WeeklyAnalysisResponse{
		ProductID:       productID,
		ProductName:     productName,
		AnalysisPeriod:  fmt.Sprintf("%s ~ %s", startDate.Format("2006-01-02"), endDate.Format("2006-01-02")),
		TotalWeeks:      len(weeklySummaries),
		WeeklySummary:   weeklySummaries,
		OverallStats:    overallStats,
		Trends:          trends,
		Recommendations: recommendations,
		Granularity:     granularity,
	}, nil
}

// groupByWeek ãƒ‡ãƒ¼ã‚¿ã‚’é€±å˜ä½ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆæœˆæ›œå§‹ã¾ã‚Šï¼‰
func (s *StatisticsService) groupByWeek(data []models.SalesDataPoint, startDate time.Time) map[int][]models.SalesDataPoint {
	weeklyGroups := make(map[int][]models.SalesDataPoint)

	for _, point := range data {
		date, err := time.Parse("2006-01-02", point.Date)
		if err != nil {
			continue
		}

		// é–‹å§‹æ—¥ã‹ã‚‰ã®é€±æ•°ã‚’è¨ˆç®—ï¼ˆæœˆæ›œå§‹ã¾ã‚Šï¼‰
		weekNum := s.getWeekNumber(date, startDate)
		weeklyGroups[weekNum] = append(weeklyGroups[weekNum], point)
	}

	return weeklyGroups
}

// groupByDay ãƒ‡ãƒ¼ã‚¿ã‚’æ—¥æ¬¡ã§ã‚µãƒãƒªãƒ¼åŒ–ï¼ˆé›†ç´„ãªã—ï¼‰
func (s *StatisticsService) groupByDay(data []models.SalesDataPoint) []models.WeeklySummary {
	summaries := make([]models.WeeklySummary, 0, len(data))
	var prevSales float64 = 0

	for i, point := range data {
		_, err := time.Parse("2006-01-02", point.Date)
		if err != nil {
			continue
		}

		var changeRate float64
		if prevSales > 0 {
			changeRate = ((point.Sales - prevSales) / prevSales) * 100
		}

		summaries = append(summaries, models.WeeklySummary{
			WeekNumber:     i + 1,
			WeekStart:      point.Date,
			WeekEnd:        point.Date,
			TotalSales:     point.Sales,
			AverageSales:   point.Sales,
			MinSales:       point.Sales,
			MaxSales:       point.Sales,
			BusinessDays:   1,
			WeekOverWeek:   changeRate,
			StdDev:         0,
			AvgTemperature: point.Temperature,
		})

		prevSales = point.Sales
	}

	return summaries
}

// groupByMonth ãƒ‡ãƒ¼ã‚¿ã‚’æœˆæ¬¡ã§é›†ç´„
func (s *StatisticsService) groupByMonth(data []models.SalesDataPoint, startDate time.Time) []models.WeeklySummary {
	monthlyGroups := make(map[string][]models.SalesDataPoint)

	// æœˆã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
	for _, point := range data {
		date, err := time.Parse("2006-01-02", point.Date)
		if err != nil {
			continue
		}
		monthKey := date.Format("2006-01")
		monthlyGroups[monthKey] = append(monthlyGroups[monthKey], point)
	}

	// ã‚½ãƒ¼ãƒˆç”¨ã«ã‚­ãƒ¼ã‚’å–å¾—
	monthKeys := make([]string, 0, len(monthlyGroups))
	for key := range monthlyGroups {
		monthKeys = append(monthKeys, key)
	}
	sort.Strings(monthKeys)

	// ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
	summaries := make([]models.WeeklySummary, 0, len(monthKeys))
	var prevMonthSales float64 = 0

	for i, monthKey := range monthKeys {
		monthData := monthlyGroups[monthKey]
		if len(monthData) == 0 {
			continue
		}

		// æœˆã®é–‹å§‹ãƒ»çµ‚äº†æ—¥ã‚’å–å¾—
		firstDate, _ := time.Parse("2006-01-02", monthData[0].Date)
		lastDate, _ := time.Parse("2006-01-02", monthData[len(monthData)-1].Date)

		// åˆè¨ˆãƒ»å¹³å‡ãƒ»æœ€å°ãƒ»æœ€å¤§ã‚’è¨ˆç®—
		var total, avgTemp, min, max, sumSquaredDiff float64
		min = math.MaxFloat64
		max = -math.MaxFloat64

		for _, point := range monthData {
			total += point.Sales
			avgTemp += point.Temperature
			if point.Sales < min {
				min = point.Sales
			}
			if point.Sales > max {
				max = point.Sales
			}
		}

		businessDays := len(monthData)
		average := total / float64(businessDays)
		avgTemp = avgTemp / float64(businessDays)

		// å‰æœˆæ¯”ã‚’è¨ˆç®—
		var monthOverMonth float64
		if prevMonthSales > 0 {
			monthOverMonth = ((total - prevMonthSales) / prevMonthSales) * 100
		}

		// æ¨™æº–åå·®ã‚’è¨ˆç®—
		for _, point := range monthData {
			diff := point.Sales - average
			sumSquaredDiff += diff * diff
		}
		stdDev := math.Sqrt(sumSquaredDiff / float64(businessDays))

		summaries = append(summaries, models.WeeklySummary{
			WeekNumber:     i + 1,
			WeekStart:      firstDate.Format("2006-01-02"),
			WeekEnd:        lastDate.Format("2006-01-02"),
			TotalSales:     total,
			AverageSales:   average,
			MinSales:       min,
			MaxSales:       max,
			BusinessDays:   businessDays,
			WeekOverWeek:   monthOverMonth,
			StdDev:         stdDev,
			AvgTemperature: avgTemp,
		})

		prevMonthSales = total
	}

	return summaries
}

// getWeekNumber é–‹å§‹æ—¥ã‹ã‚‰ã®é€±ç•ªå·ã‚’è¨ˆç®—ï¼ˆæœˆæ›œå§‹ã¾ã‚Šï¼‰
func (s *StatisticsService) getWeekNumber(date, startDate time.Time) int {
	// æœˆæ›œæ—¥ã«èª¿æ•´
	startMonday := s.adjustToMonday(startDate)
	dateMonday := s.adjustToMonday(date)

	daysDiff := dateMonday.Sub(startMonday).Hours() / 24
	weekNum := int(daysDiff) / 7

	if weekNum < 0 {
		weekNum = 0
	}

	return weekNum
}

// adjustToMonday æ—¥ä»˜ã‚’ãã®é€±ã®æœˆæ›œæ—¥ã«èª¿æ•´
func (s *StatisticsService) adjustToMonday(date time.Time) time.Time {
	weekday := int(date.Weekday())
	if weekday == 0 { // æ—¥æ›œæ—¥
		weekday = 7
	}
	daysToMonday := weekday - 1
	return date.AddDate(0, 0, -daysToMonday)
}

// calculateWeeklySummary é€±ã”ã¨ã®ã‚µãƒãƒªãƒ¼ã‚’è¨ˆç®—
func (s *StatisticsService) calculateWeeklySummary(weekNum int, weekData []models.SalesDataPoint, prevWeekSales float64) models.WeeklySummary {
	if len(weekData) == 0 {
		return models.WeeklySummary{WeekNumber: weekNum}
	}

	// é€±ã®é–‹å§‹æ—¥ãƒ»çµ‚äº†æ—¥ã‚’å–å¾—
	firstDate, _ := time.Parse("2006-01-02", weekData[0].Date)
	lastDate, _ := time.Parse("2006-01-02", weekData[len(weekData)-1].Date)

	// åˆè¨ˆãƒ»å¹³å‡ãƒ»æœ€å°ãƒ»æœ€å¤§ã‚’è¨ˆç®—
	var total, avgTemp float64
	min := math.MaxFloat64
	max := -math.MaxFloat64

	for _, point := range weekData {
		total += point.Sales
		avgTemp += point.Temperature
		if point.Sales < min {
			min = point.Sales
		}
		if point.Sales > max {
			max = point.Sales
		}
	}

	businessDays := len(weekData)
	average := total / float64(businessDays)
	avgTemp = avgTemp / float64(businessDays)

	// å‰é€±æ¯”ã‚’è¨ˆç®—
	var weekOverWeek float64
	if prevWeekSales > 0 {
		weekOverWeek = ((total - prevWeekSales) / prevWeekSales) * 100
	}

	// æ¨™æº–åå·®ã‚’è¨ˆç®—
	var sumSquaredDiff float64
	for _, point := range weekData {
		diff := point.Sales - average
		sumSquaredDiff += diff * diff
	}
	stdDev := math.Sqrt(sumSquaredDiff / float64(businessDays))

	return models.WeeklySummary{
		WeekNumber:     weekNum + 1, // 1å§‹ã¾ã‚Šã«
		WeekStart:      firstDate.Format("2006-01-02"),
		WeekEnd:        lastDate.Format("2006-01-02"),
		TotalSales:     total,
		AverageSales:   average,
		MinSales:       min,
		MaxSales:       max,
		BusinessDays:   businessDays,
		WeekOverWeek:   weekOverWeek,
		StdDev:         stdDev,
		AvgTemperature: avgTemp,
	}
}

// calculateWeeklyOverallStats å…¨ä½“çµ±è¨ˆã‚’è¨ˆç®—
func (s *StatisticsService) calculateWeeklyOverallStats(summaries []models.WeeklySummary) models.WeeklyOverallStats {
	if len(summaries) == 0 {
		return models.WeeklyOverallStats{}
	}

	// é€±æ¬¡å£²ä¸Šã‚’é›†è¨ˆ
	weeklySales := make([]float64, len(summaries))
	var total float64
	var bestWeek, worstWeek int
	var bestSales, worstSales float64 = -1, math.MaxFloat64

	for i, summary := range summaries {
		weeklySales[i] = summary.TotalSales
		total += summary.TotalSales

		if summary.TotalSales > bestSales {
			bestSales = summary.TotalSales
			bestWeek = summary.WeekNumber
		}
		if summary.TotalSales < worstSales {
			worstSales = summary.TotalSales
			worstWeek = summary.WeekNumber
		}
	}

	avgWeeklySales := total / float64(len(summaries))

	// ä¸­å¤®å€¤ã‚’è¨ˆç®—
	sortedSales := make([]float64, len(weeklySales))
	copy(sortedSales, weeklySales)
	sort.Float64s(sortedSales)

	var median float64
	mid := len(sortedSales) / 2
	if len(sortedSales)%2 == 0 {
		median = (sortedSales[mid-1] + sortedSales[mid]) / 2
	} else {
		median = sortedSales[mid]
	}

	// æ¨™æº–åå·®ã‚’è¨ˆç®—
	var sumSquaredDiff float64
	for _, sales := range weeklySales {
		diff := sales - avgWeeklySales
		sumSquaredDiff += diff * diff
	}
	stdDev := math.Sqrt(sumSquaredDiff / float64(len(weeklySales)))

	// æˆé•·ç‡ã‚’è¨ˆç®—ï¼ˆæœ€åˆã®é€± vs æœ€å¾Œã®é€±ï¼‰
	var growthRate float64
	if len(summaries) >= 2 && summaries[0].TotalSales > 0 {
		firstWeek := summaries[0].TotalSales
		lastWeek := summaries[len(summaries)-1].TotalSales
		growthRate = ((lastWeek - firstWeek) / firstWeek) * 100
	}

	// å¤‰å‹•ä¿‚æ•°ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰
	var volatility float64
	if avgWeeklySales > 0 {
		volatility = stdDev / avgWeeklySales
	}

	return models.WeeklyOverallStats{
		AverageWeeklySales: avgWeeklySales,
		MedianWeeklySales:  median,
		StdDevWeeklySales:  stdDev,
		BestWeek:           bestWeek,
		WorstWeek:          worstWeek,
		GrowthRate:         growthRate,
		Volatility:         volatility,
	}
}

// analyzeWeeklyTrends é€±æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æ
func (s *StatisticsService) analyzeWeeklyTrends(summaries []models.WeeklySummary) models.WeeklyTrends {
	if len(summaries) < 2 {
		return models.WeeklyTrends{Direction: "ãƒ‡ãƒ¼ã‚¿ä¸è¶³"}
	}

	// å‰é€±æ¯”ã®å¹³å‡ã‚’è¨ˆç®—
	var totalGrowth float64
	var positiveWeeks, negativeWeeks int
	var peakWeek, lowWeek int
	var peakSales, lowSales float64 = -1, math.MaxFloat64

	for i, summary := range summaries {
		if i > 0 { // æœ€åˆã®é€±ã¯ã‚¹ã‚­ãƒƒãƒ—
			totalGrowth += summary.WeekOverWeek
			if summary.WeekOverWeek > 0 {
				positiveWeeks++
			} else if summary.WeekOverWeek < 0 {
				negativeWeeks++
			}
		}

		if summary.TotalSales > peakSales {
			peakSales = summary.TotalSales
			peakWeek = summary.WeekNumber
		}
		if summary.TotalSales < lowSales {
			lowSales = summary.TotalSales
			lowWeek = summary.WeekNumber
		}
	}

	avgGrowth := totalGrowth / float64(len(summaries)-1)

	// ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘ã‚’åˆ¤å®š
	var direction string
	var strength float64

	if avgGrowth > 2 {
		direction = "ä¸Šæ˜‡"
		strength = math.Min(avgGrowth/10, 1.0)
	} else if avgGrowth < -2 {
		direction = "ä¸‹é™"
		strength = math.Min(math.Abs(avgGrowth)/10, 1.0)
	} else {
		direction = "æ¨ªã°ã„"
		strength = 1.0 - math.Min(math.Abs(avgGrowth)/2, 1.0)
	}

	// å­£ç¯€æ€§ã®æ¤œå‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
	var seasonality string
	if len(summaries) >= 4 {
		// å‰åŠã¨å¾ŒåŠã§æ¯”è¼ƒ
		midPoint := len(summaries) / 2
		var firstHalfAvg, secondHalfAvg float64

		for i := 0; i < midPoint; i++ {
			firstHalfAvg += summaries[i].TotalSales
		}
		firstHalfAvg /= float64(midPoint)

		for i := midPoint; i < len(summaries); i++ {
			secondHalfAvg += summaries[i].TotalSales
		}
		secondHalfAvg /= float64(len(summaries) - midPoint)

		diff := ((secondHalfAvg - firstHalfAvg) / firstHalfAvg) * 100
		if diff > 15 {
			seasonality = "å¾ŒåŠæœŸã«éœ€è¦å¢—åŠ å‚¾å‘"
		} else if diff < -15 {
			seasonality = "å‰åŠæœŸã«éœ€è¦é›†ä¸­å‚¾å‘"
		} else {
			seasonality = "æ˜ç¢ºãªå­£ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã—"
		}
	}

	return models.WeeklyTrends{
		Direction:     direction,
		Strength:      strength,
		Seasonality:   seasonality,
		PeakWeek:      peakWeek,
		LowWeek:       lowWeek,
		AverageGrowth: avgGrowth,
	}
}

// generateWeeklyRecommendations é€±æ¬¡åˆ†æã«åŸºã¥ãæ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
func (s *StatisticsService) generateWeeklyRecommendations(summaries []models.WeeklySummary, stats models.WeeklyOverallStats, trends models.WeeklyTrends) []string {
	var recommendations []string

	// ãƒˆãƒ¬ãƒ³ãƒ‰ã«åŸºã¥ãæ¨å¥¨
	switch trends.Direction {
	case "ä¸Šæ˜‡":
		recommendations = append(recommendations,
			fmt.Sprintf("ğŸ“ˆ ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆå¹³å‡+%.1f%%/é€±ï¼‰ï¼šéœ€è¦å¢—åŠ ã«å‚™ãˆã¦ç”Ÿç”£èƒ½åŠ›ã®ç¢ºä¿ã‚’æ¨å¥¨", trends.AverageGrowth))
	case "ä¸‹é™":
		recommendations = append(recommendations,
			fmt.Sprintf("ğŸ“‰ ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆå¹³å‡%.1f%%/é€±ï¼‰ï¼šåœ¨åº«æœ€é©åŒ–ã¨ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å¼·åŒ–ã‚’æ¤œè¨", trends.AverageGrowth))
	case "æ¨ªã°ã„":
		recommendations = append(recommendations,
			"ğŸ“Š å®‰å®šã—ãŸéœ€è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼šç¾çŠ¶ã®ç”Ÿç”£è¨ˆç”»ã‚’ç¶­æŒã™ã‚‹ã“ã¨ã‚’æ¨å¥¨")
	}

	// ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«åŸºã¥ãæ¨å¥¨
	if stats.Volatility > 0.3 {
		recommendations = append(recommendations,
			fmt.Sprintf("âš ï¸ éœ€è¦å¤‰å‹•ãŒå¤§ãã„ã§ã™ï¼ˆå¤‰å‹•ä¿‚æ•°: %.2fï¼‰ï¼šå®‰å…¨åœ¨åº«ã®ç¢ºä¿ã‚’æ¨å¥¨", stats.Volatility))
	} else if stats.Volatility < 0.15 {
		recommendations = append(recommendations,
			"âœ… éœ€è¦ãŒå®‰å®šã—ã¦ã„ã¾ã™ï¼šJITç”Ÿç”£æ–¹å¼ã®é©ç”¨ã‚’æ¤œè¨å¯èƒ½")
	}

	// ãƒ™ã‚¹ãƒˆãƒ»ãƒ¯ãƒ¼ã‚¹ãƒˆé€±ã«åŸºã¥ãæ¨å¥¨
	if stats.BestWeek > 0 && stats.WorstWeek > 0 {
		recommendations = append(recommendations,
			fmt.Sprintf("ğŸ“… ç¬¬%dé€±ãŒæœ€é«˜ã€ç¬¬%dé€±ãŒæœ€ä½éœ€è¦ï¼šãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã§ç”Ÿç”£è¨ˆç”»ã‚’æœ€é©åŒ–", stats.BestWeek, stats.WorstWeek))
	}

	// æˆé•·ç‡ã«åŸºã¥ãæ¨å¥¨
	if stats.GrowthRate > 20 {
		recommendations = append(recommendations,
			fmt.Sprintf("ğŸš€ æœŸé–“å…¨ä½“ã§%.1f%%æˆé•·ï¼šéœ€è¦æ€¥å¢—ã«å¯¾å¿œã—ãŸä¾›çµ¦ä½“åˆ¶ã®å¼·åŒ–ãŒå¿…è¦", stats.GrowthRate))
	} else if stats.GrowthRate < -20 {
		recommendations = append(recommendations,
			fmt.Sprintf("ğŸ“Š æœŸé–“å…¨ä½“ã§%.1f%%æ¸›å°‘ï¼šéœ€è¦å›å¾©æ–½ç­–ã®ç«‹æ¡ˆã‚’æ¨å¥¨", stats.GrowthRate))
	}

	// å­£ç¯€æ€§ã«åŸºã¥ãæ¨å¥¨
	if trends.Seasonality != "æ˜ç¢ºãªå­£ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã—" {
		recommendations = append(recommendations,
			fmt.Sprintf("ğŸŒ¤ï¸ %sï¼šå­£ç¯€è¦å› ã‚’è€ƒæ…®ã—ãŸåœ¨åº«ç®¡ç†ã‚’å®Ÿæ–½", trends.Seasonality))
	}

	return recommendations
}
