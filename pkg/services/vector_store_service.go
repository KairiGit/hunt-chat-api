package services

import (
	"context"
	"crypto/tls"
	"encoding/json"
	"fmt"
	"log"
	"sort"
	"time"

	"hunt-chat-api/pkg/models"

	"github.com/google/uuid"
	"github.com/qdrant/go-client/qdrant"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials"
	"google.golang.org/grpc/credentials/insecure"
	"google.golang.org/grpc/metadata"
)

// VectorStoreService ã¯Qdrantã¨ã®ã‚„ã‚Šå–ã‚Šã‚’ç®¡ç†ã—ã¾ã™
type VectorStoreService struct {
	qdrantClient            qdrant.PointsClient
	qdrantCollectionsClient qdrant.CollectionsClient
	azureOpenAIService      *AzureOpenAIService
}

// NewVectorStoreService ã¯æ–°ã—ã„VectorStoreServiceã‚’åˆæœŸåŒ–ã—ã¦è¿”ã—ã¾ã™
func NewVectorStoreService(azureOpenAIService *AzureOpenAIService, qdrantURL string, qdrantAPIKey string) (*VectorStoreService, error) {
	// æ¥ç¶šã‚ªãƒ—ã‚·ãƒ§ãƒ³
	var dialOpts []grpc.DialOption

	// APIã‚­ãƒ¼ã®æœ‰ç„¡ã§ã€Cloudæ¥ç¶š(TLS+APIã‚­ãƒ¼)ã¨ãƒ­ãƒ¼ã‚«ãƒ«æ¥ç¶š(éã‚»ã‚­ãƒ¥ã‚¢)ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
	if qdrantAPIKey != "" {
		// --- Qdrant Cloudç”¨ã®æ¥ç¶š --- //
		log.Println("Qdrant Cloud (TLS) ã¸ã®æ¥ç¶šã‚’æº–å‚™ã—ã¾ã™...")
		creds := credentials.NewTLS(&tls.Config{})
		dialOpts = append(dialOpts, grpc.WithTransportCredentials(creds))

		// APIã‚­ãƒ¼èªè¨¼ã‚¤ãƒ³ã‚¿ãƒ¼ã‚»ãƒ—ã‚¿ã‚’è¿½åŠ 
		authInterceptor := func(ctx context.Context, method string, req, reply interface{}, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption) error {
			ctx = metadata.AppendToOutgoingContext(ctx, "api-key", qdrantAPIKey)
			return invoker(ctx, method, req, reply, cc, opts...)
		}
		dialOpts = append(dialOpts, grpc.WithUnaryInterceptor(authInterceptor))

	} else {
		// --- ãƒ­ãƒ¼ã‚«ãƒ«ç”¨ã®æ¥ç¶š (ä»¥å‰æˆåŠŸã—ãŸæ–¹å¼) --- //
		log.Println("ãƒ­ãƒ¼ã‚«ãƒ«ã®Qdrant (éTLS) ã¸ã®æ¥ç¶šã‚’æº–å‚™ã—ã¾ã™...")
		dialOpts = append(dialOpts, grpc.WithTransportCredentials(insecure.NewCredentials()))
	}

	// gRPCæ¥ç¶šã‚’ç¢ºç«‹
	conn, err := grpc.NewClient(qdrantURL, dialOpts...)
	if err != nil {
		return nil, fmt.Errorf("Qdrantã¸ã®gRPCã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: %w", err)
	}

	qdrantPointsClient := qdrant.NewPointsClient(conn)
	qdrantCollectionsClient := qdrant.NewCollectionsClient(conn)

	collectionName := "hunt_chat_documents"
	vectorSize := uint64(1536) // text-embedding-3-smallã®æ¬¡å…ƒæ•°

	// Qdrantã‚µãƒ¼ãƒãƒ¼ãŒå®Œå…¨ã«èµ·å‹•ã™ã‚‹ã¾ã§ãƒªãƒˆãƒ©ã‚¤ã—ãªãŒã‚‰ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å­˜åœ¨ç¢ºèªã‚’è¡Œã†
	maxRetries := 10
	retryInterval := 2 * time.Second
	var collectionExists bool
	var listErr error

	log.Println("Qdrantã‚µãƒ¼ãƒãƒ¼ã®æº–å‚™ã‚’ç¢ºèªä¸­...")
	for i := 0; i < maxRetries; i++ {
		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
		res, err := qdrantCollectionsClient.List(ctx, &qdrant.ListCollectionsRequest{})
		cancel()
		listErr = err
		if err == nil {
			log.Println("Qdrantã‚µãƒ¼ãƒãƒ¼ã®æº–å‚™ãŒã§ãã¾ã—ãŸã€‚")
			for _, collection := range res.GetCollections() {
				if collection.GetName() == collectionName {
					collectionExists = true
					break
				}
			}
			break // æˆåŠŸã—ãŸã®ã§ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
		}
		log.Printf("Qdrantã‚µãƒ¼ãƒãƒ¼ã®æº–å‚™ç¢ºèªã«å¤±æ•—ã—ã¾ã—ãŸ (è©¦è¡Œ %d/%d)ã€‚%vå¾Œã«å†è©¦è¡Œã—ã¾ã™...", i+1, maxRetries, retryInterval)
		time.Sleep(retryInterval)
	}

	if listErr != nil {
		return nil, fmt.Errorf("Qdrantã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒªã‚¹ãƒˆå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒªãƒˆãƒ©ã‚¤ä¸Šé™åˆ°é”ï¼‰: %w", listErr)
	}

	// ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
	if !collectionExists {
		log.Printf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€æ–°è¦ä½œæˆã—ã¾ã™ã€‚", collectionName)
		ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
		defer cancel()
		_, err = qdrantCollectionsClient.Create(ctx, &qdrant.CreateCollection{
			CollectionName: collectionName,
			VectorsConfig: &qdrant.VectorsConfig{
				Config: &qdrant.VectorsConfig_Params{
					Params: &qdrant.VectorParams{
						Size:     vectorSize,
						Distance: qdrant.Distance_Cosine,
					},
				},
			},
		})
		if err != nil {
			return nil, fmt.Errorf("Qdrantã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: %w", err)
		}
		log.Printf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ã‚’ä½œæˆã—ã¾ã—ãŸã€‚", collectionName)
	} else {
		log.Printf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚", collectionName)
	}

	return &VectorStoreService{
		qdrantClient:            qdrantPointsClient,
		qdrantCollectionsClient: qdrantCollectionsClient,
		azureOpenAIService:      azureOpenAIService,
	}, nil
}

// Save ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨å…±ã«Qdrantã«ä¿å­˜ã—ã¾ã™ã€‚
func (s *VectorStoreService) Save(ctx context.Context, text string, metadata map[string]interface{}) error {
	// 1. ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
	vector, err := s.azureOpenAIService.CreateEmbedding(ctx, text)
	if err != nil {
		return fmt.Errorf("ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«å¤±æ•—: %w", err)
	}

	// 2. Qdrantã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’ä½œæˆ
	payload := make(map[string]*qdrant.Value)
	for key, value := range metadata {
		// å‹ã‚¹ã‚¤ãƒƒãƒã§qdrant.Valueã«å¤‰æ›
		switch v := value.(type) {
		case string:
			payload[key] = &qdrant.Value{Kind: &qdrant.Value_StringValue{StringValue: v}}
		case int:
			payload[key] = &qdrant.Value{Kind: &qdrant.Value_IntegerValue{IntegerValue: int64(v)}}
		case float64:
			payload[key] = &qdrant.Value{Kind: &qdrant.Value_DoubleValue{DoubleValue: v}}
		case bool:
			payload[key] = &qdrant.Value{Kind: &qdrant.Value_BoolValue{BoolValue: v}}
		}
	}
	// å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚‚ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã«å«ã‚ã‚‹
	payload["text"] = &qdrant.Value{
		Kind: &qdrant.Value_StringValue{StringValue: text},
	}

	// 3. Qdrantã«ä¿å­˜ã™ã‚‹Pointã‚’ä½œæˆ
	pointId := uuid.New().String()
	points := []*qdrant.PointStruct{
		{
			Id: &qdrant.PointId{
				PointIdOptions: &qdrant.PointId_Uuid{Uuid: pointId},
			},
			Vectors: &qdrant.Vectors{
				VectorsOptions: &qdrant.Vectors_Vector{
					Vector: &qdrant.Vector{
						Data: vector,
					},
				},
			},
			Payload: payload,
		},
	}

	// 4. Qdrantã«Upsert
	collectionName := "hunt_chat_documents"
	waitUpsert := true
	_, err = s.qdrantClient.Upsert(ctx, &qdrant.UpsertPoints{
		CollectionName: collectionName,
		Points:         points,
		Wait:           &waitUpsert,
	})

	if err != nil {
		return fmt.Errorf("Qdrantã¸ã®ãƒ™ã‚¯ãƒˆãƒ«ä¿å­˜ã«å¤±æ•—: %w", err)
	}

	log.Printf("ID '%s' ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’Qdrantã«ä¿å­˜ã—ã¾ã—ãŸã€‚", pointId)
	return nil
}

// Search ã¯ã‚¯ã‚¨ãƒªãƒ†ã‚­ã‚¹ãƒˆã«é¡ä¼¼ã—ãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’Qdrantã‹ã‚‰æ¤œç´¢ã—ã¾ã™ã€‚
func (s *VectorStoreService) Search(ctx context.Context, queryText string, topK uint64) ([]*qdrant.ScoredPoint, error) {
	// 1. ã‚¯ã‚¨ãƒªãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
	queryVector, err := s.azureOpenAIService.CreateEmbedding(ctx, queryText)
	if err != nil {
		return nil, fmt.Errorf("ã‚¯ã‚¨ãƒªãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«å¤±æ•—: %w", err)
	}

	// 2. Qdrantã§é¡ä¼¼ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ¤œç´¢
	collectionName := "hunt_chat_documents"
	withPayload := true
	searchResult, err := s.qdrantClient.Search(ctx, &qdrant.SearchPoints{
		CollectionName: collectionName,
		Vector:         queryVector,
		Limit:          topK,
		WithPayload:    &qdrant.WithPayloadSelector{SelectorOptions: &qdrant.WithPayloadSelector_Enable{Enable: withPayload}},
	})
	if err != nil {
		return nil, fmt.Errorf("Qdrantã§ã®ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã«å¤±æ•—: %w", err)
	}

	log.Printf("'%s' ã«é¡ä¼¼ã—ãŸ %d ä»¶ã®çµæœã‚’Qdrantã‹ã‚‰å–å¾—ã—ã¾ã—ãŸã€‚", queryText, len(searchResult.GetResult()))
	return searchResult.GetResult(), nil
}

// SaveAnalysisReport åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’æ§‹é€ åŒ–ã—ã¦Qdrantã«ä¿å­˜
func (s *VectorStoreService) SaveAnalysisReport(ctx context.Context, report interface{}, reportType string) error {
	// ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONæ–‡å­—åˆ—ã«å¤‰æ›
	var reportText string
	switch r := report.(type) {
	case string:
		reportText = r
	default:
		// æ§‹é€ ä½“ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¦ä¿å­˜
		reportText = fmt.Sprintf("%+v", r)
	}

	metadata := map[string]interface{}{
		"type":        "analysis_report",
		"report_type": reportType,
		"timestamp":   time.Now().Format(time.RFC3339),
		"source":      "statistical_analysis",
	}

	return s.Save(ctx, reportText, metadata)
}

// SearchAnalysisReports åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’æ¤œç´¢ï¼ˆtypeãƒ•ã‚£ãƒ«ã‚¿ä»˜ãï¼‰
func (s *VectorStoreService) SearchAnalysisReports(ctx context.Context, query string, topK uint64) ([]*qdrant.ScoredPoint, error) {
	// ã‚¯ã‚¨ãƒªãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
	queryVector, err := s.azureOpenAIService.CreateEmbedding(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("ã‚¯ã‚¨ãƒªãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«å¤±æ•—: %w", err)
	}

	// typeãƒ•ã‚£ãƒ«ã‚¿ã‚’è¿½åŠ 
	collectionName := "hunt_chat_documents"
	withPayload := true

	// Qdrantã®ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’æ§‹ç¯‰
	filter := &qdrant.Filter{
		Must: []*qdrant.Condition{
			{
				ConditionOneOf: &qdrant.Condition_Field{
					Field: &qdrant.FieldCondition{
						Key: "type",
						Match: &qdrant.Match{
							MatchValue: &qdrant.Match_Keyword{
								Keyword: "analysis_report",
							},
						},
					},
				},
			},
		},
	}

	searchResult, err := s.qdrantClient.Search(ctx, &qdrant.SearchPoints{
		CollectionName: collectionName,
		Vector:         queryVector,
		Limit:          topK,
		Filter:         filter,
		WithPayload:    &qdrant.WithPayloadSelector{SelectorOptions: &qdrant.WithPayloadSelector_Enable{Enable: withPayload}},
	})
	if err != nil {
		return nil, fmt.Errorf("åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®æ¤œç´¢ã«å¤±æ•—: %w", err)
	}

	log.Printf("åˆ†æãƒ¬ãƒãƒ¼ãƒˆæ¤œç´¢: '%s' ã«é¡ä¼¼ã—ãŸ %d ä»¶ã‚’å–å¾—", query, len(searchResult.GetResult()))
	return searchResult.GetResult(), nil
}

// GetAllAnalysisReportHeaders ã¯ã™ã¹ã¦ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã‚’å–å¾—ã—ã¾ã™
func (s *VectorStoreService) GetAllAnalysisReportHeaders(ctx context.Context) ([]models.AnalysisReportHeader, error) {
	collectionName := "hunt_chat_documents"
	points, err := s.ScrollAllPoints(ctx, collectionName, 1000) // æœ€å¤§1000ä»¶ã¾ã§å–å¾—
	if err != nil {
		return nil, fmt.Errorf("ãƒ¬ãƒãƒ¼ãƒˆã®å–å¾—ã«å¤±æ•—: %w", err)
	}

	var headers []models.AnalysisReportHeader
	for _, point := range points {
		if point.Payload != nil && point.Payload["type"] != nil && point.Payload["type"].GetStringValue() == "analysis_report" {
			headers = append(headers, models.AnalysisReportHeader{
				ReportID:     point.Id.GetUuid(),
				FileName:     getStringFromPayload(point.Payload, "file_name"),
				AnalysisDate: getStringFromPayload(point.Payload, "analysis_date"),
				// DateRangeã¯ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã«ãªã„ã®ã§ã€å¿…è¦ã§ã‚ã‚Œã°åˆ¥é€”è¿½åŠ ã™ã‚‹
			})
		}
	}

	// æ—¥ä»˜ã®é™é †ï¼ˆæ–°ã—ã„ã‚‚ã®ãŒå…ˆï¼‰ã«ã‚½ãƒ¼ãƒˆ
	sort.Slice(headers, func(i, j int) bool {
		t1, _ := time.Parse(time.RFC3339, headers[i].AnalysisDate)
		t2, _ := time.Parse(time.RFC3339, headers[j].AnalysisDate)
		return t1.After(t2)
	})

	log.Printf("%dä»¶ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å–å¾—ã—ã¾ã—ãŸ", len(headers))
	return headers, nil
}

// GetAllAnalysisReports ã¯ã™ã¹ã¦ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’å®Œå…¨ã«å–å¾—ã—ã¾ã™
func (s *VectorStoreService) GetAllAnalysisReports(ctx context.Context) ([]models.AnalysisReport, error) {
	collectionName := "hunt_chat_documents"
	points, err := s.ScrollAllPoints(ctx, collectionName, 1000) // æœ€å¤§1000ä»¶ã¾ã§å–å¾—
	if err != nil {
		return nil, fmt.Errorf("å…¨ãƒ¬ãƒãƒ¼ãƒˆã®å–å¾—ã«å¤±æ•—: %w", err)
	}

	var reports []models.AnalysisReport
	for _, point := range points {
		if point.Payload != nil && point.Payload["type"] != nil && point.Payload["type"].GetStringValue() == "analysis_report" {
			// â˜… textã‹ã‚‰ã§ã¯ãªãã€full_report_jsonã‹ã‚‰å–å¾—ã™ã‚‹
			reportJSON := getStringFromPayload(point.Payload, "full_report_json")
			if reportJSON == "" {
				log.Printf("ãƒ¬ãƒãƒ¼ãƒˆID %s ã« full_report_json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚", point.Id.GetUuid())
				continue
			}
			var report models.AnalysisReport
			if err := json.Unmarshal([]byte(reportJSON), &report); err == nil {
				reports = append(reports, report)
			} else {
				log.Printf("ãƒ¬ãƒãƒ¼ãƒˆJSONã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•— (GetAllAnalysisReports): %v", err)
			}
		}
	}

	log.Printf("%dä»¶ã®å®Œå…¨ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ", len(reports))
	return reports, nil
}

// GetAllAnomalyResponses ã¯ã™ã¹ã¦ã®ç•°å¸¸å›ç­”ã‚’å–å¾—ã—ã¾ã™
func (s *VectorStoreService) GetAllAnomalyResponses(ctx context.Context) ([]models.AnomalyResponse, error) {
	collectionName := "anomaly_responses"
	points, err := s.ScrollAllPoints(ctx, collectionName, 10000) // ååˆ†ãªæ•°ã‚’å–å¾—
	if err != nil {
		return nil, fmt.Errorf("å…¨ç•°å¸¸å›ç­”ã®å–å¾—ã«å¤±æ•—: %w", err)
	}

	var responses []models.AnomalyResponse
	for _, point := range points {
		if point.Payload == nil {
			continue
		}

		// textãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‹ã‚‰å›ç­”ã®JSONæ–‡å­—åˆ—ã‚’å–å¾—ã—ãƒ‘ãƒ¼ã‚¹ã™ã‚‹
		// SaveAnomalyResponseã®å®Ÿè£…ã«åˆã‚ã›ã¦ä¿®æ­£
		responseText := getStringFromPayload(point.Payload, "text")
		var response models.AnomalyResponse

		// ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‹ã‚‰ç›´æ¥ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’èª­ã¿è¾¼ã‚€æ–¹ãŒç¢ºå®Ÿ
		response.ResponseID = getStringFromPayload(point.Payload, "response_id")
		response.AnomalyDate = getStringFromPayload(point.Payload, "anomaly_date")
		response.ProductID = getStringFromPayload(point.Payload, "product_id")
		response.Question = getStringFromPayload(point.Payload, "question")
		response.Answer = getStringFromPayload(point.Payload, "answer")

		if response.AnomalyDate != "" && response.ProductID != "" {
			responses = append(responses, response)
		} else if responseText != "" {
			// textã‹ã‚‰ã®ãƒ‘ãƒ¼ã‚¹ã‚‚è©¦ã¿ã‚‹ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
			// ã“ã®éƒ¨åˆ†ã¯SaveAnomalyResponseã®å®Ÿè£…ã«ä¾å­˜ã—ã¾ã™
			// ç¾åœ¨ã®å®Ÿè£…ã§ã¯textã«JSONã¯å…¥ã£ã¦ã„ãªã„ãŸã‚ã€ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ãŒãƒ¡ã‚¤ãƒ³
			continue
		}
	}

	log.Printf("%dä»¶ã®ç•°å¸¸å›ç­”ã‚’å–å¾—ã—ã¾ã—ãŸ", len(responses))
	return responses, nil
}

// GetAnalysisReportByID ã¯IDã§å˜ä¸€ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—ã—ã¾ã™
func (s *VectorStoreService) GetAnalysisReportByID(ctx context.Context, reportID string) (*models.AnalysisReport, error) {
	collectionName := "hunt_chat_documents"

	// IDã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦Scrollã§å–å¾—
	scrollResult, err := s.qdrantClient.Scroll(ctx, &qdrant.ScrollPoints{
		CollectionName: collectionName,
		Filter: &qdrant.Filter{
			Must: []*qdrant.Condition{
				{
					ConditionOneOf: &qdrant.Condition_HasId{
						HasId: &qdrant.HasIdCondition{
							HasId: []*qdrant.PointId{
								{PointIdOptions: &qdrant.PointId_Uuid{Uuid: reportID}},
							},
						},
					},
				},
			},
		},
		Limit:       func(u uint32) *uint32 { return &u }(1),
		WithPayload: &qdrant.WithPayloadSelector{SelectorOptions: &qdrant.WithPayloadSelector_Enable{Enable: true}},
	})

	if err != nil {
		return nil, fmt.Errorf("Qdrantã‹ã‚‰ã®ãƒã‚¤ãƒ³ãƒˆå–å¾—ã«å¤±æ•—: %w", err)
	}

	if len(scrollResult.GetResult()) == 0 {
		return nil, fmt.Errorf("ãƒ¬ãƒãƒ¼ãƒˆID '%s' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", reportID)
	}

	point := scrollResult.GetResult()[0]
	if point.Payload == nil || point.Payload["type"] == nil || point.Payload["type"].GetStringValue() != "analysis_report" {
		return nil, fmt.Errorf("ãƒã‚¤ãƒ³ãƒˆ '%s' ã¯åˆ†æãƒ¬ãƒãƒ¼ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“", reportID)
	}

	// â˜… textã‹ã‚‰ã§ã¯ãªãã€full_report_jsonã‹ã‚‰å–å¾—ã™ã‚‹
	reportJSON := getStringFromPayload(point.Payload, "full_report_json")
	if reportJSON == "" {
		return nil, fmt.Errorf("ãƒ¬ãƒãƒ¼ãƒˆID '%s' ã« full_report_json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", reportID)
	}

	var report models.AnalysisReport
	if err := json.Unmarshal([]byte(reportJSON), &report); err != nil {
		return nil, fmt.Errorf("ãƒ¬ãƒãƒ¼ãƒˆJSONã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—: %w", err)
	}

	log.Printf("ãƒ¬ãƒãƒ¼ãƒˆ '%s' ã‚’å–å¾—ã—ã¾ã—ãŸ", reportID)
	return &report, nil
}

// DeleteAllAnalysisReports ã¯ã™ã¹ã¦ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’å‰Šé™¤ã—ã¾ã™
func (s *VectorStoreService) DeleteAllAnalysisReports(ctx context.Context) error {
	collectionName := "hunt_chat_documents"
	points, err := s.ScrollAllPoints(ctx, collectionName, 10000) // Adjust limit as needed
	if err != nil {
		return fmt.Errorf("ãƒ¬ãƒãƒ¼ãƒˆã®å–å¾—ã«å¤±æ•—: %w", err)
	}

	var idsToDelete []*qdrant.PointId
	for _, point := range points {
		if point.Payload == nil {
			continue
		}
		if payloadType, ok := point.Payload["type"]; ok && payloadType != nil {
			if payloadType.GetStringValue() == "analysis_report" {
				idsToDelete = append(idsToDelete, point.Id)
			}
		}
	}

	if len(idsToDelete) == 0 {
		log.Println("å‰Šé™¤å¯¾è±¡ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
		return nil
	}

	waitDelete := true
	_, err = s.qdrantClient.Delete(ctx, &qdrant.DeletePoints{
		CollectionName: collectionName,
		Wait:           &waitDelete,
		Points: &qdrant.PointsSelector{
			PointsSelectorOneOf: &qdrant.PointsSelector_Points{
				Points: &qdrant.PointsIdsList{Ids: idsToDelete},
			},
		},
	})

	if err != nil {
		return fmt.Errorf("Qdrantã‹ã‚‰ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆå‰Šé™¤ã«å¤±æ•—: %w", err)
	}

	log.Printf("%dä»¶ã®åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸ", len(idsToDelete))
	return nil
}

// StoreDocument ã¯æŒ‡å®šã•ã‚ŒãŸã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜ï¼ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’æŒ‡å®šå¯èƒ½ï¼‰
func (s *VectorStoreService) StoreDocument(ctx context.Context, collectionName string, documentID string, text string, metadata map[string]interface{}) error {
	// ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã€ãªã‘ã‚Œã°ä½œæˆ
	if err := s.ensureCollection(ctx, collectionName); err != nil {
		return fmt.Errorf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®æº–å‚™ã«å¤±æ•—: %w", err)
	}

	// 1. ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
	vector, err := s.azureOpenAIService.CreateEmbedding(ctx, text)
	if err != nil {
		return fmt.Errorf("ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«å¤±æ•—: %w", err)
	}

	// 2. Qdrantã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’ä½œæˆ
	payload := make(map[string]*qdrant.Value)
	for key, value := range metadata {
		switch v := value.(type) {
		case string:
			payload[key] = &qdrant.Value{Kind: &qdrant.Value_StringValue{StringValue: v}}
		case int:
			payload[key] = &qdrant.Value{Kind: &qdrant.Value_IntegerValue{IntegerValue: int64(v)}}
		case int64:
			payload[key] = &qdrant.Value{Kind: &qdrant.Value_IntegerValue{IntegerValue: v}}
		case float64:
			payload[key] = &qdrant.Value{Kind: &qdrant.Value_DoubleValue{DoubleValue: v}}
		case bool:
			payload[key] = &qdrant.Value{Kind: &qdrant.Value_BoolValue{BoolValue: v}}
		}
	}
	// å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚‚ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã«å«ã‚ã‚‹
	payload["text"] = &qdrant.Value{
		Kind: &qdrant.Value_StringValue{StringValue: text},
	}

	// 3. Qdrantã«ä¿å­˜ã™ã‚‹Pointã‚’ä½œæˆ
	points := []*qdrant.PointStruct{
		{
			Id: &qdrant.PointId{
				PointIdOptions: &qdrant.PointId_Uuid{Uuid: documentID},
			},
			Vectors: &qdrant.Vectors{
				VectorsOptions: &qdrant.Vectors_Vector{
					Vector: &qdrant.Vector{
						Data: vector,
					},
				},
			},
			Payload: payload,
		},
	}

	// 4. Qdrantã«Upsert
	waitUpsert := true
	_, err = s.qdrantClient.Upsert(ctx, &qdrant.UpsertPoints{
		CollectionName: collectionName,
		Points:         points,
		Wait:           &waitUpsert,
	})

	if err != nil {
		return fmt.Errorf("Qdrantã¸ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¿å­˜ã«å¤±æ•—: %w", err)
	}

	log.Printf("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ '%s' ã‚’ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚", documentID, collectionName)
	return nil
}

// SearchWithFilter ã¯ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ä»˜ãã§æ¤œç´¢
func (s *VectorStoreService) SearchWithFilter(ctx context.Context, collectionName string, queryText string, topK uint64, filter *qdrant.Filter) ([]*qdrant.ScoredPoint, error) {
	// ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å­˜åœ¨ã‚’ç¢ºèª
	if err := s.ensureCollection(ctx, collectionName); err != nil {
		return nil, fmt.Errorf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ç¢ºèªã«å¤±æ•—: %w", err)
	}

	// 1. ã‚¯ã‚¨ãƒªãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
	queryVector, err := s.azureOpenAIService.CreateEmbedding(ctx, queryText)
	if err != nil {
		return nil, fmt.Errorf("ã‚¯ã‚¨ãƒªãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«å¤±æ•—: %w", err)
	}

	// 2. Qdrantã§é¡ä¼¼ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ¤œç´¢ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ä»˜ãï¼‰
	withPayload := true
	searchResult, err := s.qdrantClient.Search(ctx, &qdrant.SearchPoints{
		CollectionName: collectionName,
		Vector:         queryVector,
		Limit:          topK,
		Filter:         filter,
		WithPayload:    &qdrant.WithPayloadSelector{SelectorOptions: &qdrant.WithPayloadSelector_Enable{Enable: withPayload}},
	})
	if err != nil {
		return nil, fmt.Errorf("Qdrantã§ã®ãƒ•ã‚£ãƒ«ã‚¿ä»˜ãæ¤œç´¢ã«å¤±æ•—: %w", err)
	}

	log.Printf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ã§ãƒ•ã‚£ãƒ«ã‚¿ä»˜ãæ¤œç´¢: %d ä»¶å–å¾—", collectionName, len(searchResult.GetResult()))
	return searchResult.GetResult(), nil
}

// ScrollAllPoints æŒ‡å®šã—ãŸã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å…¨ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãªã—ï¼‰
func (s *VectorStoreService) ScrollAllPoints(ctx context.Context, collectionName string, limit uint32) ([]*qdrant.RetrievedPoint, error) {
	// ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å­˜åœ¨ã‚’ç¢ºèª
	if err := s.ensureCollection(ctx, collectionName); err != nil {
		return nil, fmt.Errorf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ç¢ºèªã«å¤±æ•—: %w", err)
	}

	withPayload := true
	scrollResult, err := s.qdrantClient.Scroll(ctx, &qdrant.ScrollPoints{
		CollectionName: collectionName,
		Limit:          &limit,
		WithPayload:    &qdrant.WithPayloadSelector{SelectorOptions: &qdrant.WithPayloadSelector_Enable{Enable: withPayload}},
	})

	if err != nil {
		return nil, fmt.Errorf("Qdrantã§ã®å…¨ä»¶å–å¾—ã«å¤±æ•—: %w", err)
	}

	log.Printf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ã‹ã‚‰ %d ä»¶å–å¾—", collectionName, len(scrollResult.GetResult()))
	return scrollResult.GetResult(), nil
}

// DeletePoint æŒ‡å®šã—ãŸIDã®ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤
func (s *VectorStoreService) DeletePoint(ctx context.Context, collectionName string, pointID string) error {
	// ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å­˜åœ¨ã‚’ç¢ºèª
	if err := s.ensureCollection(ctx, collectionName); err != nil {
		return fmt.Errorf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ç¢ºèªã«å¤±æ•—: %w", err)
	}

	waitDelete := true
	_, err := s.qdrantClient.Delete(ctx, &qdrant.DeletePoints{
		CollectionName: collectionName,
		Wait:           &waitDelete,
		Points: &qdrant.PointsSelector{
			PointsSelectorOneOf: &qdrant.PointsSelector_Points{
				Points: &qdrant.PointsIdsList{
					Ids: []*qdrant.PointId{
						{
							PointIdOptions: &qdrant.PointId_Uuid{
								Uuid: pointID,
							},
						},
					},
				},
			},
		},
	})

	if err != nil {
		return fmt.Errorf("Qdrantã‹ã‚‰ã®ãƒã‚¤ãƒ³ãƒˆå‰Šé™¤ã«å¤±æ•—: %w", err)
	}

	log.Printf("ãƒã‚¤ãƒ³ãƒˆ '%s' ã‚’ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ã‹ã‚‰å‰Šé™¤ã—ã¾ã—ãŸ", pointID, collectionName)
	return nil
}

// DeleteDocumentByFileName ã¯æŒ‡å®šã—ãŸfile_nameã‚’æŒã¤å…¨ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤
func (s *VectorStoreService) DeleteDocumentByFileName(ctx context.Context, collectionName string, fileName string) error {
	// ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å­˜åœ¨ç¢ºèª
	if err := s.ensureCollection(ctx, collectionName); err != nil {
		return fmt.Errorf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ç¢ºèªã«å¤±æ•—: %w", err)
	}

	// file_nameã§ãƒ•ã‚£ãƒ«ã‚¿ã—ã¦å…¨ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
	filter := &qdrant.Filter{
		Must: []*qdrant.Condition{
			{
				ConditionOneOf: &qdrant.Condition_Field{
					Field: &qdrant.FieldCondition{
						Key: "file_name",
						Match: &qdrant.Match{
							MatchValue: &qdrant.Match_Keyword{
								Keyword: fileName,
							},
						},
					},
				},
			},
		},
	}

	withPayload := false
	limit := uint32(1000) // æœ€å¤§1000ãƒãƒ£ãƒ³ã‚¯
	scrollResult, err := s.qdrantClient.Scroll(ctx, &qdrant.ScrollPoints{
		CollectionName: collectionName,
		Filter:         filter,
		Limit:          &limit,
		WithPayload:    &qdrant.WithPayloadSelector{SelectorOptions: &qdrant.WithPayloadSelector_Enable{Enable: withPayload}},
	})
	if err != nil {
		return fmt.Errorf("ãƒã‚¤ãƒ³ãƒˆå–å¾—ã«å¤±æ•—: %w", err)
	}

	points := scrollResult.GetResult()
	if len(points) == 0 {
		// åˆå›å®Ÿè¡Œæ™‚ã¯å‰Šé™¤å¯¾è±¡ãŒãªã„ã®ã§ã€ã“ã‚Œã¯ã‚¨ãƒ©ãƒ¼ã§ã¯ãªã„
		return nil
	}

	// ãƒã‚¤ãƒ³ãƒˆIDã‚’åé›†
	var idsToDelete []*qdrant.PointId
	for _, point := range points {
		idsToDelete = append(idsToDelete, point.Id)
	}

	// å‰Šé™¤å®Ÿè¡Œ
	waitDelete := true
	_, err = s.qdrantClient.Delete(ctx, &qdrant.DeletePoints{
		CollectionName: collectionName,
		Wait:           &waitDelete,
		Points: &qdrant.PointsSelector{
			PointsSelectorOneOf: &qdrant.PointsSelector_Points{
				Points: &qdrant.PointsIdsList{Ids: idsToDelete},
			},
		},
	})
	if err != nil {
		return fmt.Errorf("ãƒã‚¤ãƒ³ãƒˆå‰Šé™¤ã«å¤±æ•—: %w", err)
	}

	log.Printf("  ğŸ—‘ï¸ %d å€‹ã®å¤ã„ãƒãƒ£ãƒ³ã‚¯ã‚’å‰Šé™¤ã—ã¾ã—ãŸ", len(idsToDelete))
	return nil
}

// EnsureEconomicCollection ensures the economic_daily_summaries collection exists and indexes are set.
func (s *VectorStoreService) EnsureEconomicCollection(ctx context.Context) error {
	collectionName := "economic_daily_summaries"
	if err := s.ensureCollection(ctx, collectionName); err != nil {
		return err
	}
	// Create indexes on symbol and date for efficient filtering
	fieldType := qdrant.FieldType_FieldTypeKeyword
	// symbol
	idxCtx, cancelIdx := context.WithTimeout(ctx, 10*time.Second)
	defer cancelIdx()
	_, err := s.qdrantClient.CreateFieldIndex(idxCtx, &qdrant.CreateFieldIndexCollection{
		CollectionName: collectionName,
		FieldName:      "symbol",
		FieldType:      &fieldType,
	})
	if err != nil {
		log.Printf("â„¹ï¸ symbol index create (maybe exists): %v", err)
	}
	// date
	idxCtx2, cancelIdx2 := context.WithTimeout(ctx, 10*time.Second)
	defer cancelIdx2()
	_, err = s.qdrantClient.CreateFieldIndex(idxCtx2, &qdrant.CreateFieldIndexCollection{
		CollectionName: collectionName,
		FieldName:      "date",
		FieldType:      &fieldType,
	})
	if err != nil {
		log.Printf("â„¹ï¸ date index create (maybe exists): %v", err)
	}
	return nil
}

// GetLatestEconomicDate returns the max date (YYYY-MM-DD) stored for a symbol.
func (s *VectorStoreService) GetLatestEconomicDate(ctx context.Context, symbol string) (string, error) {
	collectionName := "economic_daily_summaries"
	if err := s.ensureCollection(ctx, collectionName); err != nil {
		return "", err
	}

	// Build filter: type == economic_daily AND symbol == symbol
	filter := &qdrant.Filter{
		Must: []*qdrant.Condition{
			{
				ConditionOneOf: &qdrant.Condition_Field{Field: &qdrant.FieldCondition{
					Key:   "type",
					Match: &qdrant.Match{MatchValue: &qdrant.Match_Keyword{Keyword: "economic_daily"}},
				}},
			},
			{
				ConditionOneOf: &qdrant.Condition_Field{Field: &qdrant.FieldCondition{
					Key:   "symbol",
					Match: &qdrant.Match{MatchValue: &qdrant.Match_Keyword{Keyword: symbol}},
				}},
			},
		},
	}

	limit := uint32(10000)
	withPayload := true
	scrollCtx, cancel := context.WithTimeout(ctx, 20*time.Second)
	defer cancel()
	res, err := s.qdrantClient.Scroll(scrollCtx, &qdrant.ScrollPoints{
		CollectionName: collectionName,
		Filter:         filter,
		Limit:          &limit,
		WithPayload:    &qdrant.WithPayloadSelector{SelectorOptions: &qdrant.WithPayloadSelector_Enable{Enable: withPayload}},
	})
	if err != nil {
		return "", fmt.Errorf("failed to scroll economic points: %w", err)
	}
	latest := ""
	for _, p := range res.GetResult() {
		d := getStringFromPayload(p.Payload, "date")
		if d > latest { // lexicographical works for YYYY-MM-DD
			latest = d
		}
	}
	return latest, nil
}

// GetEconomicSeries fetches economic daily series for a symbol between start and end (inclusive), sorted by date asc.
func (s *VectorStoreService) GetEconomicSeries(ctx context.Context, symbol string, start, end time.Time) ([]struct{ Date string; Value float64 }, error) {
	collectionName := "economic_daily_summaries"
	if err := s.ensureCollection(ctx, collectionName); err != nil {
		return nil, err
	}

	// Filter by type and symbol; we'll post-filter dates client-side
	filter := &qdrant.Filter{
		Must: []*qdrant.Condition{
			{ConditionOneOf: &qdrant.Condition_Field{Field: &qdrant.FieldCondition{Key: "type", Match: &qdrant.Match{MatchValue: &qdrant.Match_Keyword{Keyword: "economic_daily"}}}}},
			{ConditionOneOf: &qdrant.Condition_Field{Field: &qdrant.FieldCondition{Key: "symbol", Match: &qdrant.Match{MatchValue: &qdrant.Match_Keyword{Keyword: symbol}}}}},
		},
	}
	limit := uint32(100000)
	withPayload := true
	scrollCtx, cancel := context.WithTimeout(ctx, 25*time.Second)
	defer cancel()
	res, err := s.qdrantClient.Scroll(scrollCtx, &qdrant.ScrollPoints{
		CollectionName: collectionName,
		Filter:         filter,
		Limit:          &limit,
		WithPayload:    &qdrant.WithPayloadSelector{SelectorOptions: &qdrant.WithPayloadSelector_Enable{Enable: withPayload}},
	})
	if err != nil {
		return nil, fmt.Errorf("failed to scroll economic series: %w", err)
	}
	startStr := start.Format("2006-01-02")
	endStr := end.Format("2006-01-02")
	out := make([]struct{ Date string; Value float64 }, 0, len(res.GetResult()))
	for _, p := range res.GetResult() {
		if p.Payload == nil { continue }
		d := getStringFromPayload(p.Payload, "date")
		if d == "" { continue }
		if d < startStr || d > endStr { continue }
		var val float64
		if v := p.Payload["value"]; v != nil {
			val = v.GetDoubleValue()
		}
		out = append(out, struct{ Date string; Value float64 }{Date: d, Value: val})
	}
	sort.Slice(out, func(i, j int) bool { return out[i].Date < out[j].Date })
	return out, nil
}

// StoreEconomicDailyBatch stores daily economic points for a symbol, embedding textual summaries.
func (s *VectorStoreService) StoreEconomicDailyBatch(ctx context.Context, symbol string, points []struct {
	Date  string
	Value float64
}) error {
	collectionName := "economic_daily_summaries"
	// Ensure collection with a short timeout
	ensureCtx, cancelEnsure := context.WithTimeout(ctx, 15*time.Second)
	defer cancelEnsure()
	if err := s.EnsureEconomicCollection(ensureCtx); err != nil {
		return err
	}

	// Build points
	qpoints := make([]*qdrant.PointStruct, 0, len(points))
	// Economic daily summaries don't need semantic search now; avoid slow embeddings.
	// Use a fixed zero vector with the known dimension (1536) to satisfy Qdrant schema.
	zeroVec := make([]float32, 1536)
	for _, pt := range points {
		text := fmt.Sprintf("%s %s Close=%.4f", pt.Date, symbol, pt.Value)
		payload := map[string]*qdrant.Value{
			"type":   {Kind: &qdrant.Value_StringValue{StringValue: "economic_daily"}},
			"symbol": {Kind: &qdrant.Value_StringValue{StringValue: symbol}},
			"date":   {Kind: &qdrant.Value_StringValue{StringValue: pt.Date}},
			"value":  {Kind: &qdrant.Value_DoubleValue{DoubleValue: pt.Value}},
			"text":   {Kind: &qdrant.Value_StringValue{StringValue: text}},
		}
		// use deterministic UUID (v5/SHA1) derived from "symbol:date" for idempotency
		rawID := fmt.Sprintf("%s:%s", symbol, pt.Date)
		idStr := uuid.NewSHA1(uuid.NameSpaceURL, []byte(rawID)).String()
		qpoints = append(qpoints, &qdrant.PointStruct{
			Id:      &qdrant.PointId{PointIdOptions: &qdrant.PointId_Uuid{Uuid: idStr}},
			Vectors: &qdrant.Vectors{VectorsOptions: &qdrant.Vectors_Vector{Vector: &qdrant.Vector{Data: zeroVec}}},
			Payload: payload,
		})
	}
	if len(qpoints) == 0 {
		return nil
	}
	wait := true
	// Bound upsert to avoid long hangs
	upsertCtx, cancelUpsert := context.WithTimeout(ctx, 20*time.Second)
	defer cancelUpsert()
	_, err := s.qdrantClient.Upsert(upsertCtx, &qdrant.UpsertPoints{
		CollectionName: collectionName,
		Points:         qpoints,
		Wait:           &wait,
	})
	if err != nil {
		return fmt.Errorf("upsert economic points failed: %w", err)
	}
	log.Printf("âœ… Stored %d economic points for %s", len(qpoints), symbol)
	return nil
}

// EnsureSalesCollection ensures the sales_daily_series collection exists and indexes are set.
func (s *VectorStoreService) EnsureSalesCollection(ctx context.Context) error {
	collectionName := "sales_daily_series"
	if err := s.ensureCollection(ctx, collectionName); err != nil {
		return err
	}
	fieldType := qdrant.FieldType_FieldTypeKeyword
	// product_id
	ctx1, cancel1 := context.WithTimeout(ctx, 10*time.Second)
	defer cancel1()
	if _, err := s.qdrantClient.CreateFieldIndex(ctx1, &qdrant.CreateFieldIndexCollection{
		CollectionName: collectionName,
		FieldName:      "product_id",
		FieldType:      &fieldType,
	}); err != nil {
		log.Printf("â„¹ï¸ product_id index create (maybe exists): %v", err)
	}
	// date
	ctx2, cancel2 := context.WithTimeout(ctx, 10*time.Second)
	defer cancel2()
	if _, err := s.qdrantClient.CreateFieldIndex(ctx2, &qdrant.CreateFieldIndexCollection{
		CollectionName: collectionName,
		FieldName:      "date",
		FieldType:      &fieldType,
	}); err != nil {
		log.Printf("â„¹ï¸ date index create (maybe exists): %v", err)
	}
	return nil
}

// GetLatestSalesDate returns the max date (YYYY-MM-DD) stored for a product.
func (s *VectorStoreService) GetLatestSalesDate(ctx context.Context, productID string) (string, error) {
	collectionName := "sales_daily_series"
	if err := s.ensureCollection(ctx, collectionName); err != nil {
		return "", err
	}
	filter := &qdrant.Filter{
		Must: []*qdrant.Condition{
			{ConditionOneOf: &qdrant.Condition_Field{Field: &qdrant.FieldCondition{Key: "type", Match: &qdrant.Match{MatchValue: &qdrant.Match_Keyword{Keyword: "sales_daily"}}}}},
			{ConditionOneOf: &qdrant.Condition_Field{Field: &qdrant.FieldCondition{Key: "product_id", Match: &qdrant.Match{MatchValue: &qdrant.Match_Keyword{Keyword: productID}}}}},
		},
	}
	limit := uint32(100000)
	withPayload := true
	ctxScroll, cancel := context.WithTimeout(ctx, 20*time.Second)
	defer cancel()
	res, err := s.qdrantClient.Scroll(ctxScroll, &qdrant.ScrollPoints{
		CollectionName: collectionName,
		Filter:         filter,
		Limit:          &limit,
		WithPayload:    &qdrant.WithPayloadSelector{SelectorOptions: &qdrant.WithPayloadSelector_Enable{Enable: withPayload}},
	})
	if err != nil {
		return "", fmt.Errorf("failed to scroll sales points: %w", err)
	}
	latest := ""
	for _, p := range res.GetResult() {
		d := getStringFromPayload(p.Payload, "date")
		if d > latest { latest = d }
	}
	return latest, nil
}

// StoreSalesDailyBatch stores daily sales points for a product.
func (s *VectorStoreService) StoreSalesDailyBatch(ctx context.Context, productID string, points []struct{ Date string; Sales float64 }) error {
	collectionName := "sales_daily_series"
	// Ensure collection with timeout
	ectx, cancelE := context.WithTimeout(ctx, 15*time.Second)
	defer cancelE()
	if err := s.EnsureSalesCollection(ectx); err != nil { return err }

	// Prepare points with zero vector
	zeroVec := make([]float32, 1536)
	qpoints := make([]*qdrant.PointStruct, 0, len(points))
	for _, pt := range points {
		text := fmt.Sprintf("%s %s Sales=%.4f", pt.Date, productID, pt.Sales)
		payload := map[string]*qdrant.Value{
			"type":       {Kind: &qdrant.Value_StringValue{StringValue: "sales_daily"}},
			"product_id": {Kind: &qdrant.Value_StringValue{StringValue: productID}},
			"date":       {Kind: &qdrant.Value_StringValue{StringValue: pt.Date}},
			"sales":      {Kind: &qdrant.Value_DoubleValue{DoubleValue: pt.Sales}},
			"text":       {Kind: &qdrant.Value_StringValue{StringValue: text}},
		}
		rawID := fmt.Sprintf("%s:%s", productID, pt.Date)
		idStr := uuid.NewSHA1(uuid.NameSpaceURL, []byte(rawID)).String()
		qpoints = append(qpoints, &qdrant.PointStruct{
			Id:      &qdrant.PointId{PointIdOptions: &qdrant.PointId_Uuid{Uuid: idStr}},
			Vectors: &qdrant.Vectors{VectorsOptions: &qdrant.Vectors_Vector{Vector: &qdrant.Vector{Data: zeroVec}}},
			Payload: payload,
		})
	}
	if len(qpoints) == 0 { return nil }
	wait := true
	uctx, cancelU := context.WithTimeout(ctx, 20*time.Second)
	defer cancelU()
	if _, err := s.qdrantClient.Upsert(uctx, &qdrant.UpsertPoints{CollectionName: collectionName, Points: qpoints, Wait: &wait}); err != nil {
		return fmt.Errorf("upsert sales points failed: %w", err)
	}
	log.Printf("âœ… Stored %d sales points for %s", len(qpoints), productID)
	return nil
}

// GetSalesSeries fetches sales daily series for a product between start and end.
func (s *VectorStoreService) GetSalesSeries(ctx context.Context, productID string, start, end time.Time) ([]struct{ Date string; Sales float64 }, error) {
	collectionName := "sales_daily_series"
	if err := s.ensureCollection(ctx, collectionName); err != nil { return nil, err }
	filter := &qdrant.Filter{
		Must: []*qdrant.Condition{
			{ConditionOneOf: &qdrant.Condition_Field{Field: &qdrant.FieldCondition{Key: "type", Match: &qdrant.Match{MatchValue: &qdrant.Match_Keyword{Keyword: "sales_daily"}}}}},
			{ConditionOneOf: &qdrant.Condition_Field{Field: &qdrant.FieldCondition{Key: "product_id", Match: &qdrant.Match{MatchValue: &qdrant.Match_Keyword{Keyword: productID}}}}},
		},
	}
	limit := uint32(100000)
	withPayload := true
	sctx, cancel := context.WithTimeout(ctx, 25*time.Second)
	defer cancel()
	res, err := s.qdrantClient.Scroll(sctx, &qdrant.ScrollPoints{
		CollectionName: collectionName,
		Filter:         filter,
		Limit:          &limit,
		WithPayload:    &qdrant.WithPayloadSelector{SelectorOptions: &qdrant.WithPayloadSelector_Enable{Enable: withPayload}},
	})
	if err != nil { return nil, fmt.Errorf("failed to scroll sales series: %w", err) }
	startStr := start.Format("2006-01-02")
	endStr := end.Format("2006-01-02")
	out := make([]struct{ Date string; Sales float64 }, 0, len(res.GetResult()))
	for _, p := range res.GetResult() {
		if p.Payload == nil { continue }
		d := getStringFromPayload(p.Payload, "date")
		if d == "" || d < startStr || d > endStr { continue }
		var v float64
		if pv := p.Payload["sales"]; pv != nil { v = pv.GetDoubleValue() }
		out = append(out, struct{ Date string; Sales float64 }{Date: d, Sales: v})
	}
	sort.Slice(out, func(i, j int) bool { return out[i].Date < out[j].Date })
	return out, nil
}

// RecreateCollection ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤ã—ã¦å†ä½œæˆï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ï¼‰
func (s *VectorStoreService) RecreateCollection(ctx context.Context, collectionName string) error {
	// ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤
	deleteCtx, cancel := context.WithTimeout(ctx, 10*time.Second)
	defer cancel()

	_, err := s.qdrantCollectionsClient.Delete(deleteCtx, &qdrant.DeleteCollection{
		CollectionName: collectionName,
	})

	if err != nil {
		log.Printf("è­¦å‘Š: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤ã«å¤±æ•—ï¼ˆç¶šè¡Œã—ã¾ã™ï¼‰: %v", err)
	} else {
		log.Printf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ã‚’å‰Šé™¤ã—ã¾ã—ãŸ", collectionName)
	}

	// ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å†ä½œæˆ
	createCtx, cancel := context.WithTimeout(ctx, 10*time.Second)
	defer cancel()

	vectorSize := uint64(1536) // text-embedding-3-smallã®æ¬¡å…ƒæ•°
	_, err = s.qdrantCollectionsClient.Create(createCtx, &qdrant.CreateCollection{
		CollectionName: collectionName,
		VectorsConfig: &qdrant.VectorsConfig{
			Config: &qdrant.VectorsConfig_Params{
				Params: &qdrant.VectorParams{
					Size:     vectorSize,
					Distance: qdrant.Distance_Cosine,
				},
			},
		},
	})

	if err != nil {
		return fmt.Errorf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å†ä½œæˆã«å¤±æ•—: %w", err)
	}

	log.Printf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ã‚’å†ä½œæˆã—ã¾ã—ãŸ", collectionName)
	return nil
}

// ensureCollection ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ãªã‘ã‚Œã°ä½œæˆ
func (s *VectorStoreService) ensureCollection(ctx context.Context, collectionName string) error {
	log.Printf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ã®å­˜åœ¨ã‚’ç¢ºèªä¸­...", collectionName)

	// ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
	listCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()

	res, err := s.qdrantCollectionsClient.List(listCtx, &qdrant.ListCollectionsRequest{})
	if err != nil {
		log.Printf("è­¦å‘Š: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒªã‚¹ãƒˆã®å–å¾—ã«å¤±æ•—ï¼ˆç¶šè¡Œã—ã¾ã™ï¼‰: %v", err)
		return nil // ã‚¨ãƒ©ãƒ¼ã§ã‚‚ç¶šè¡Œï¼ˆæ—¢å­˜ã®å ´åˆã¯Upsertæ™‚ã«æˆåŠŸã™ã‚‹ï¼‰
	}

	// ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
	collectionExists := false
	for _, collection := range res.GetCollections() {
		if collection.GetName() == collectionName {
			collectionExists = true
			break
		}
	}

	// å­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
	if !collectionExists {
		log.Printf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ã‚’ä½œæˆã—ã¾ã™...", collectionName)
		createCtx, cancel := context.WithTimeout(ctx, 10*time.Second)
		defer cancel()

		vectorSize := uint64(1536) // text-embedding-3-smallã®æ¬¡å…ƒæ•°
		_, err = s.qdrantCollectionsClient.Create(createCtx, &qdrant.CreateCollection{
			CollectionName: collectionName,
			VectorsConfig: &qdrant.VectorsConfig{
				Config: &qdrant.VectorsConfig_Params{
					Params: &qdrant.VectorParams{
						Size:     vectorSize,
						Distance: qdrant.Distance_Cosine,
					},
				},
			},
		})
		if err != nil {
			log.Printf("è­¦å‘Š: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆã«å¤±æ•—ï¼ˆç¶šè¡Œã—ã¾ã™ï¼‰: %v", err)
			return nil // ã‚¨ãƒ©ãƒ¼ã§ã‚‚ç¶šè¡Œ
		}
		log.Printf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ã‚’ä½œæˆã—ã¾ã—ãŸ", collectionName)

		// file_name ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆï¼ˆãƒ•ã‚£ãƒ«ã‚¿æ¤œç´¢ç”¨ï¼‰
		indexCtx, cancel := context.WithTimeout(ctx, 10*time.Second)
		defer cancel()

		fieldType := qdrant.FieldType_FieldTypeKeyword
		_, err = s.qdrantClient.CreateFieldIndex(indexCtx, &qdrant.CreateFieldIndexCollection{
			CollectionName: collectionName,
			FieldName:      "file_name",
			FieldType:      &fieldType,
		})
		if err != nil {
			log.Printf("âš ï¸ file_name ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã«å¤±æ•—ï¼ˆç¶šè¡Œã—ã¾ã™ï¼‰: %v", err)
		} else {
			log.Printf("âœ… file_name ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¾ã—ãŸ")
		}

		log.Printf("ğŸ“Œ é‡è¦: 'type' ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã«ã¯ã€Qdrantã«è‡ªå‹•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒä½œæˆã•ã‚Œã¾ã™")
	} else {
		log.Printf("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '%s' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™", collectionName)

		// æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ã‚‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå¿…è¦ã‹ç¢ºèªã—ã¦ä½œæˆ
		indexCtx, cancel := context.WithTimeout(ctx, 10*time.Second)
		defer cancel()

		fieldType := qdrant.FieldType_FieldTypeKeyword
		_, err := s.qdrantClient.CreateFieldIndex(indexCtx, &qdrant.CreateFieldIndexCollection{
			CollectionName: collectionName,
			FieldName:      "file_name",
			FieldType:      &fieldType,
		})
		if err != nil {
			// ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŒã€å•é¡Œãªã„
			log.Printf("  ğŸ’¡ file_name ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯æ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ã€ä½œæˆä¸è¦ã§ã™")
		} else {
			log.Printf("  âœ… æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã« file_name ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
		}
	}

	return nil
}

// SaveChatHistory ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’Qdrantã«ä¿å­˜
func (s *VectorStoreService) SaveChatHistory(ctx context.Context, entry models.ChatHistoryEntry) error {
	collectionName := "chat_history"

	// ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’JSONæ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç”¨ã«æº–å‚™
	entryText := fmt.Sprintf(
		"Role: %s\nMessage: %s\nContext: %s\nTags: %v\nIntent: %s\nProductID: %s",
		entry.Role,
		entry.Message,
		entry.Context,
		entry.Tags,
		entry.Metadata.Intent,
		entry.Metadata.ProductID,
	)

	// ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
	metadata := map[string]interface{}{
		"type":       "chat_history",
		"session_id": entry.SessionID,
		"user_id":    entry.UserID,
		"role":       entry.Role,
		"timestamp":  entry.Timestamp,
		"intent":     entry.Metadata.Intent,
		"product_id": entry.Metadata.ProductID,
		"date_range": entry.Metadata.DateRange,
	}

	// ã‚¿ã‚°ã‚’JSONæ–‡å­—åˆ—ã¨ã—ã¦è¿½åŠ 
	if len(entry.Tags) > 0 {
		tagsJSON, _ := json.Marshal(entry.Tags)
		metadata["tags"] = string(tagsJSON)
	}

	// ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’JSONæ–‡å­—åˆ—ã¨ã—ã¦è¿½åŠ 
	if len(entry.Metadata.TopicKeywords) > 0 {
		keywordsJSON, _ := json.Marshal(entry.Metadata.TopicKeywords)
		metadata["keywords"] = string(keywordsJSON)
	}

	// ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã—ã¦ä¿å­˜ï¼ˆæ—¢å­˜ã®StoreDocumentãƒ¡ã‚½ãƒƒãƒ‰ã‚’æ´»ç”¨ï¼‰
	return s.StoreDocument(ctx, collectionName, entry.ID, entryText, metadata)
}

// SearchChatHistory ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’æ¤œç´¢ï¼ˆRAGæ©Ÿèƒ½ï¼‰
func (s *VectorStoreService) SearchChatHistory(ctx context.Context, query string, sessionID string, userID string, topK uint64) ([]models.ChatHistoryEntry, error) {
	collectionName := "chat_history"

	// ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’æ§‹ç¯‰
	var filterConditions []*qdrant.Condition

	// typeãƒ•ã‚£ãƒ«ã‚¿ã¯å¿…é ˆ
	filterConditions = append(filterConditions, &qdrant.Condition{
		ConditionOneOf: &qdrant.Condition_Field{
			Field: &qdrant.FieldCondition{
				Key: "type",
				Match: &qdrant.Match{
					MatchValue: &qdrant.Match_Keyword{
						Keyword: "chat_history",
					},
				},
			},
		},
	})

	// ã‚»ãƒƒã‚·ãƒ§ãƒ³IDãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
	if sessionID != "" {
		filterConditions = append(filterConditions, &qdrant.Condition{
			ConditionOneOf: &qdrant.Condition_Field{
				Field: &qdrant.FieldCondition{
					Key: "session_id",
					Match: &qdrant.Match{
						MatchValue: &qdrant.Match_Keyword{
							Keyword: sessionID,
						},
					},
				},
			},
		})
	}

	// ãƒ¦ãƒ¼ã‚¶ãƒ¼IDãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
	if userID != "" {
		filterConditions = append(filterConditions, &qdrant.Condition{
			ConditionOneOf: &qdrant.Condition_Field{
				Field: &qdrant.FieldCondition{
					Key: "user_id",
					Match: &qdrant.Match{
						MatchValue: &qdrant.Match_Keyword{
							Keyword: userID,
						},
					},
				},
			},
		})
	}

	filter := &qdrant.Filter{
		Must: filterConditions,
	}

	// ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’å®Ÿè¡Œ
	results, err := s.SearchWithFilter(ctx, collectionName, query, topK, filter)
	if err != nil {
		return nil, fmt.Errorf("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®æ¤œç´¢ã«å¤±æ•—: %w", err)
	}

	// çµæœã‚’ ChatHistoryEntry ã«å¤‰æ›
	var entries []models.ChatHistoryEntry
	for _, result := range results {
		payload := result.GetPayload()

		entry := models.ChatHistoryEntry{
			ID:        result.Id.GetUuid(),
			SessionID: getStringFromPayload(payload, "session_id"),
			UserID:    getStringFromPayload(payload, "user_id"),
			Role:      getStringFromPayload(payload, "role"),
			Message:   getStringFromPayload(payload, "text"), // å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰å–å¾—
			Timestamp: getStringFromPayload(payload, "timestamp"),
			Metadata: models.Metadata{
				Intent:         getStringFromPayload(payload, "intent"),
				ProductID:      getStringFromPayload(payload, "product_id"),
				DateRange:      getStringFromPayload(payload, "date_range"),
				RelevanceScore: float64(result.GetScore()),
			},
		}

		// ã‚¿ã‚°ã®å¾©å…ƒ
		if tagsJSON := getStringFromPayload(payload, "tags"); tagsJSON != "" {
			var tags []string
			if err := json.Unmarshal([]byte(tagsJSON), &tags); err == nil {
				entry.Tags = tags
			}
		}

		// ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å¾©å…ƒ
		if keywordsJSON := getStringFromPayload(payload, "keywords"); keywordsJSON != "" {
			var keywords []string
			if err := json.Unmarshal([]byte(keywordsJSON), &keywords); err == nil {
				entry.Metadata.TopicKeywords = keywords
			}
		}

		entries = append(entries, entry)
	}

	log.Printf("ãƒãƒ£ãƒƒãƒˆå±¥æ­´æ¤œç´¢: %d ä»¶ã®é–¢é€£ã™ã‚‹ä¼šè©±ã‚’å–å¾—ã—ã¾ã—ãŸ", len(entries))
	return entries, nil
}

// GetRecentChatHistory æœ€è¿‘ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å–å¾—ï¼ˆæ™‚ç³»åˆ—é †ï¼‰
func (s *VectorStoreService) GetRecentChatHistory(ctx context.Context, sessionID string, limit int) ([]models.ChatHistoryEntry, error) {
	// ã“ã®æ©Ÿèƒ½ã¯ã€Qdrantã§ã¯ã‚¹ã‚³ã‚¢ãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢ã«ãªã‚‹ãŸã‚ã€
	// å®Ÿéš›ã«ã¯æ™‚ç³»åˆ—ã§ã®å–å¾—ãŒé›£ã—ã„ã€‚ä»£ã‚ã‚Šã«ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§ç›´è¿‘ã®ä¼šè©±ã‚’å–å¾—ã™ã‚‹
	// æ”¹å–„æ¡ˆ: timestampã‚’ä½¿ã£ãŸå°‚ç”¨ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹
	return s.SearchChatHistory(ctx, "æœ€è¿‘ã®ä¼šè©±", sessionID, "", uint64(limit))
}

// getStringFromPayload ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‹ã‚‰æ–‡å­—åˆ—å€¤ã‚’å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
func getStringFromPayload(payload map[string]*qdrant.Value, key string) string {
	if val, ok := payload[key]; ok {
		if strVal := val.GetStringValue(); strVal != "" {
			return strVal
		}
	}
	return ""
}

// HasAnomalyResponse ã¯æŒ‡å®šã•ã‚ŒãŸç•°å¸¸ã«å¯¾ã™ã‚‹å›ç­”ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™
func (s *VectorStoreService) HasAnomalyResponse(ctx context.Context, anomalyDate string, productID string) (bool, error) {
	collectionName := "anomaly_responses"

	// anomaly_date ã¨ product_id ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
	filter := &qdrant.Filter{
		Must: []*qdrant.Condition{
			{
				ConditionOneOf: &qdrant.Condition_Field{
					Field: &qdrant.FieldCondition{
						Key: "anomaly_date",
						Match: &qdrant.Match{
							MatchValue: &qdrant.Match_Keyword{
								Keyword: anomalyDate,
							},
						},
					},
				},
			},
			{
				ConditionOneOf: &qdrant.Condition_Field{
					Field: &qdrant.FieldCondition{
						Key: "product_id",
						Match: &qdrant.Match{
							MatchValue: &qdrant.Match_Keyword{
								Keyword: productID,
							},
						},
					},
				},
			},
		},
	}

	// æ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¯ãƒ€ãƒŸãƒ¼ã§OKã€ãƒ•ã‚£ãƒ«ã‚¿ãŒä¸»ç›®çš„ï¼‰
	// topK=1ã§ååˆ†
	searchResults, err := s.SearchWithFilter(ctx, collectionName, "anomaly check", 1, filter)
	if err != nil {
		return false, fmt.Errorf("ç•°å¸¸å›ç­”ã®å­˜åœ¨ç¢ºèªä¸­ã«æ¤œç´¢ã‚¨ãƒ©ãƒ¼: %w", err)
	}

	// çµæœãŒ1ä»¶ä»¥ä¸Šã‚ã‚Œã°ã€å›ç­”ã¯å­˜åœ¨ã™ã‚‹ã¨åˆ¤æ–­
	return len(searchResults) > 0, nil
}

// ========================================
// æ·±æ˜ã‚Šè³ªå•æ©Ÿèƒ½ã®ãŸã‚ã®æ–°ã—ã„é–¢æ•°
// ========================================

// SaveAnomalyResponseSession ç•°å¸¸å›ç­”ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã‚’Qdrantã«ä¿å­˜
func (s *VectorStoreService) SaveAnomalyResponseSession(ctx context.Context, session *models.AnomalyResponseSession) error {
	collectionName := "anomaly_response_sessions"

	// ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã‚’JSONã«å¤‰æ›
	sessionJSON, err := json.Marshal(session)
	if err != nil {
		return fmt.Errorf("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®JSONåŒ–ã«å¤±æ•—: %w", err)
	}

	// æ¤œç´¢ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ï¼ˆå…¨ä¼šè©±ã‚’é€£çµï¼‰
	var conversationText string
	for i, conv := range session.Conversations {
		conversationText += fmt.Sprintf("\nè³ªå•%d: %s\nå›ç­”%d: %s", i+1, conv.Question, i+1, conv.Answer)
	}

	searchText := fmt.Sprintf(
		"æ—¥ä»˜: %s\nè£½å“ID: %s\nä¼šè©±å±¥æ­´:%s\nã‚¿ã‚°: %s\nå½±éŸ¿: %s",
		session.AnomalyDate,
		session.ProductID,
		conversationText,
		session.FinalTags,
		session.FinalImpact,
	)

	// ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
	metadata := map[string]interface{}{
		"type":               "anomaly_response_session",
		"session_id":         session.SessionID,
		"anomaly_date":       session.AnomalyDate,
		"product_id":         session.ProductID,
		"is_complete":        session.IsComplete,
		"follow_up_count":    session.FollowUpCount,
		"conversation_count": len(session.Conversations),
		"created_at":         session.CreatedAt,
		"session_json":       string(sessionJSON), // å®Œå…¨ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
	}

	if session.CompletedAt != "" {
		metadata["completed_at"] = session.CompletedAt
	}

	// Qdrantã«ä¿å­˜
	err = s.StoreDocument(ctx, collectionName, session.SessionID, searchText, metadata)
	if err != nil {
		return fmt.Errorf("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä¿å­˜ã«å¤±æ•—: %w", err)
	}

	log.Printf("âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä¿å­˜ã—ã¾ã—ãŸ: %s (å®Œäº†: %v, ä¼šè©±æ•°: %d)",
		session.SessionID, session.IsComplete, len(session.Conversations))

	return nil
}

// GetAnomalyResponseSession ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‹ã‚‰ç•°å¸¸å›ç­”ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—
func (s *VectorStoreService) GetAnomalyResponseSession(ctx context.Context, sessionID string) (*models.AnomalyResponseSession, error) {
	collectionName := "anomaly_response_sessions"

	// Qdrantã‹ã‚‰å–å¾—
	points, err := s.qdrantClient.Get(ctx, &qdrant.GetPoints{
		CollectionName: collectionName,
		Ids:            []*qdrant.PointId{{PointIdOptions: &qdrant.PointId_Uuid{Uuid: sessionID}}},
		WithPayload:    &qdrant.WithPayloadSelector{SelectorOptions: &qdrant.WithPayloadSelector_Enable{Enable: true}},
	})

	if err != nil {
		return nil, fmt.Errorf("ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—ã«å¤±æ•—: %w", err)
	}

	if len(points.GetResult()) == 0 {
		return nil, fmt.Errorf("ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: %s", sessionID)
	}

	// session_jsonãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰å®Œå…¨ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ
	payload := points.GetResult()[0].Payload
	sessionJSONValue, ok := payload["session_json"]
	if !ok {
		return nil, fmt.Errorf("session_jsonãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
	}

	sessionJSONStr := ""
	if strVal := sessionJSONValue.GetStringValue(); strVal != "" {
		sessionJSONStr = strVal
	} else {
		return nil, fmt.Errorf("session_jsonã®å€¤ãŒå–å¾—ã§ãã¾ã›ã‚“")
	}

	// JSONã‚’ãƒ‘ãƒ¼ã‚¹
	var session models.AnomalyResponseSession
	if err := json.Unmarshal([]byte(sessionJSONStr), &session); err != nil {
		return nil, fmt.Errorf("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®JSONè§£æã«å¤±æ•—: %w", err)
	}

	return &session, nil
}
